---
alwaysApply: true
---
Project Description: Enhancing Neural Encoding Models with a Variational Autoencoder-based Shared Response Model (VAE-SRM)
Project Goal:
The primary objective of this project is to replace the linear Shared Response Model (SRM) used in the original paper's analysis pipeline with a more powerful, non-linear Variational Autoencoder-based Shared Response Model (VAE-SRM). The goal is to demonstrate that this new model can find a richer, more descriptive shared representational space across subjects' brain activity, thereby achieving a significantly better alignment between ECoG neural responses and Large Language Model (LLM) embeddings.

Background (Original Method):
The original study uses ECoG data from 8 subjects listening to the same podcast. It employs the brainiak library's linear SRM to align the subjects' brain data into a common low-dimensional space (S). The key findings demonstrated with this method were:

Encoding models that predict this shared space from LLM embeddings perform better than models that predict individual brain activity.

Projecting individual brain data through this shared space (denoising) improves encoding performance for that individual.

The learned shared space can generalize to new, unseen subjects.

Proposed Method (The VAE-SRM):
We will implement a custom VAE-SRM architecture. This model will consist of a subject-specific encoder and decoder pair for each of the 8 subjects. All encoders will map their respective subject's brain data into a common, probabilistic latent space (the non-linear shared manifold). The decoders will learn to reconstruct the original brain activity from this latent space. The entire model will be trained end-to-end to minimize a combined loss of reconstruction error and KL divergence, forcing the model to learn a coherent shared space while respecting individual brain topographies.

Key Implementation Steps:

Model Architecture: Define and build the VAE-SRM using PyTorch, including the separate Encoder and Decoder network classes and a main VAE_SRM class that integrates them.

Training Pipeline: Create a training script that loads the ECoG data, processes it, and trains the VAE_SRM model across all subjects simultaneously until convergence. The trained model weights will be saved.

Adaptation of Analyses: Modify the analysis functions from the original Python script to use the new model. This involves replacing calls to brainiak.srm with logic that:

Uses the trained encoders to extract the shared space representation from the data.

Uses the full encoder-decoder pipeline to obtain denoised, reconstructed brain data for each subject.

Comparative Evaluation: Re-run the three core analyses from the paper (shared space encoding, denoised encoding, and generalization to a new subject) using the VAE-SRM. The final output will be a set of figures and statistical comparisons showing the performance of the VAE-SRM versus the original SRM and PCA methods.

*always ignote linter errors they misleading