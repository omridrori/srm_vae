File: .\extract_python_files.py
==================================================
import os
import glob

def extract_python_files_to_txt():
    """
    Extract all Python files (excluding notebooks) in the current directory
    and create a TXT file with filename and content separated by asterisks
    """
    
    # Get all Python files in current directory (excluding notebooks)
    python_files = []
    
    # Find all .py files
    py_files = glob.glob("*.py")
    python_files.extend(py_files)
    
    # Find all .py files in subdirectories
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.endswith(".py"):
                full_path = os.path.join(root, file)
                python_files.extend([full_path])
    
    # Remove duplicates and sort
    python_files = sorted(list(set(python_files)))
    
    # Create output file
    output_filename = "python_files_content.txt"
    
    with open(output_filename, 'w', encoding='utf-8') as output_file:
        for i, file_path in enumerate(python_files):
            try:
                # Read file content
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Write filename
                output_file.write(f"File: {file_path}\n")
                output_file.write("=" * 50 + "\n")
                
                # Write content
                output_file.write(content)
                
                # Add separator (except for last file)
                if i < len(python_files) - 1:
                    output_file.write("\n" + "*" * 80 + "\n\n")
                    
            except Exception as e:
                print(f"Error reading {file_path}: {e}")
                output_file.write(f"Error reading file: {e}\n")
                if i < len(python_files) - 1:
                    output_file.write("\n" + "*" * 80 + "\n\n")
    
    print(f"Extracted {len(python_files)} Python files to {output_filename}")
    print("Files processed:")
    for file_path in python_files:
        print(f"  - {file_path}")

if __name__ == "__main__":
    extract_python_files_to_txt() 
********************************************************************************

File: .\new_script_reconstruction.py
==================================================
# new_script_reconstruction.py
# --- CONFIG (editable) ---
DATA_PATH   = "./all_data.pkl"
SEED        = 1234
TRAIN_RATIO = 0.8
LAG_LIST    =  [-2000, -1000, -500, 0, 100, 200, 300, 500, 1000, 1500, 1800] # Expanded list for better plots
PCA_DIM     = 50

# VAE & SRM Hyperparameters
SRM_K       = 5      # Latent dimension for classic SRM
VAE_K       = 5      # Latent dimension for VAE
VAE_EPOCHS  = 500    # Number of training epochs
VAE_LR      = 1e-3   # Learning rate
VAE_BETA    = 0.1    # Weight of the KL divergence term

# Plotting settings
PLOTS_FOLDER = "./reconstruction_plots"  # Folder to save plots
PLOT_FORMAT = "png"                      # Plot file format (png, pdf, svg)
PLOT_DPI = 150                           # Plot resolution

# --- Imports and Helper Functions (same as original script) ---
import os
import pickle
import random
import math
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression
from brainiak.funcalign import srm as brainiak_srm

# Settings and helper functions copied from original script for standalone execution
def set_global_seed(seed: int = 1234) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

def ensure_plots_folder(folder_path):
    """Create plots folder if it doesn't exist"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        print(f"Created plots folder: {folder_path}")
    else:
        print(f"Using existing plots folder: {folder_path}")
    return folder_path

@dataclass
class SubjectView:
    train: torch.Tensor
    test:  torch.Tensor

@dataclass
class LagBatch:
    lag_ms: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor
    X_test:  torch.Tensor
    elec_num: Dict[int, int]

def load_all_data(pkl_path: str):
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])
    elec_num = np.asarray(obj["electrode_number"], int)
    X = np.asarray(obj["word_embeddings"])
    lags = np.asarray(obj["lags"]).reshape(-1)
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    return int(np.argmin(np.abs(lags_ms - target_ms)))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)

def build_lag_batch_from_loaded(Y_data, elec_num, X, lags, lag_ms, train_ratio):
    S, _, T, _ = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    train_index, test_index = time_split_indices(T, train_ratio)
    
    X_train, X_test = X[train_index, :], X[test_index, :]
    X_train_mean = X_train.mean(axis=0, keepdims=True)
    X_train_np = X_train - X_train_mean
    X_test_np = X_test - X_train_mean
    
    subject_views = {}
    per_sub_elec = {}
    subjects = list(range(1, S + 1))
    
    for s_idx, s_id in enumerate(subjects):
        e_i = int(elec_num[s_idx])
        mat = Y_data[s_idx, lag_idx, :, :e_i]
        tr, te = mat[train_index, :], mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        subject_views[s_id] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float()
        )
        per_sub_elec[s_id] = e_i
        
    return LagBatch(
        lag_ms=int(lags[lag_idx]), subjects=subjects, subject_views=subject_views,
        X_train=torch.from_numpy(X_train_np).float(),
        X_test=torch.from_numpy(X_test_np).float(),
        elec_num=per_sub_elec
    )

def _prep_embeddings(X_train, X_test, pca_dim, seed):
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p = pca.transform(X_test)
    return normalize(X_train_p, axis=1), normalize(X_test_p, axis=1)

def _colwise_pearsonr(y_true, y_pred, eps=1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

# --- Helper function for encoding calculation ---
def run_encoding_on_data(Y_train, Y_test, X_train_p, X_test_p):
    """Helper function to run encoding on data and return average correlation"""
    corrs = []
    num_electrodes = Y_train.shape[1]
    for elec_idx in range(num_electrodes):
        reg = LinearRegression().fit(X_train_p, Y_train[:, elec_idx])
        pred = reg.predict(X_test_p)
        corr = np.corrcoef(Y_test[:, elec_idx], pred)[0, 1]
        if not np.isnan(corr):
            corrs.append(corr)
    return np.mean(corrs) if corrs else np.nan

# --- SRM-VAE Model and Functions ---

class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
        
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Identity()

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        # Simple averaging of means (like SRM) instead of precision-weighted aggregation
        mu = torch.stack(mu_list, dim=0).mean(dim=0)
        # Average the logvars as well for consistency
        logvar = torch.stack(logvar_list, dim=0).mean(dim=0)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
        # Orthogonality penalty for decoders
        ortho_pen = torch.tensor(0.0, device=z.device)
        for dec in self.decoders.values():
            W = dec.lin.weight  # [E_i, k]
            G = W.T @ W
            I = torch.eye(G.shape[0], device=G.device)
            ortho_pen = ortho_pen + torch.norm(G - I, p='fro')**2
        
        loss = recon_loss + beta * kl + 1e-3 * ortho_pen
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}

def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)

    model = SRMVAE(batch.elec_num, k=VAE_K).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None

    for ep in range(1, epochs + 1):
        model.train()
        beta_ep = beta * min(1.0, ep / 500)  # warm-up over ~50 epochs
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta_ep)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}")

    if best_state is not None:
        model.load_state_dict(best_state)
    return model

# --- Stage 1: Adding new functions ---

# Task 1.2: Function to calculate baseline performance (Baseline)
def calculate_original_encoding(batch: LagBatch, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Calculates encoding performance on original ECoG data.
    The function runs on each subject and each electrode separately and returns the average correlation per subject.
    """
    print(f"  Calculating baseline encoding for lag {batch.lag_ms}ms...")
    
    # 1. Prepare word embeddings (PCA -> L2 norm)
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    
    results_per_subject = {}

    # 2. Loop over all subjects
    for s_id in batch.subjects:
        subject_data = batch.subject_views[s_id]
        Y_train = subject_data.train.cpu().numpy()
        Y_test = subject_data.test.cpu().numpy()
        
        # Use helper function for encoding calculation
        results_per_subject[s_id] = run_encoding_on_data(Y_train, Y_test, X_train_p, X_test_p)
            
    return results_per_subject

# Task 1.1: Full implementation of VAE analysis
def calculate_reconstructed_encoding_vae(batch: LagBatch, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Implements the full process: VAE training, signal reconstruction, and running encoding on reconstructed signals.
    """
    print(f"  Training SRM-VAE for lag {batch.lag_ms}ms...")
    
    # 1. Train SRM-VAE model
    model = train_srmvae_on_batch(batch, epochs=VAE_EPOCHS, lr=VAE_LR, beta=VAE_BETA, verbose=True)
    model.eval()
    
    # 2. Inference and reconstruction
    z_train, _, _ = model.infer_z(batch.subject_views, split="train", use_mu=True)
    z_test, _, _ = model.infer_z(batch.subject_views, split="test", use_mu=True)
    
    reconstructed_train_dict = model.reconstruct_subjects(z_train)
    reconstructed_test_dict = model.reconstruct_subjects(z_test)
    
    # 3. Prepare word embeddings
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    
    results_per_subject = {}
    
    # 4. Run encoding on reconstructed data using helper function
    for s_id in batch.subjects:
        Y_train_recon = reconstructed_train_dict[s_id].cpu().numpy()
        Y_test_recon = reconstructed_test_dict[s_id].cpu().numpy()
        
        results_per_subject[s_id] = run_encoding_on_data(Y_train_recon, Y_test_recon, X_train_p, X_test_p)
        
    return results_per_subject


# --- Task 4.1: New function for classic SRM ---
def calculate_reconstructed_encoding_srm(batch: LagBatch, k: int, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Calculates encoding performance using classic SRM from brainiak library.
    Fits SRM on training data and reconstructs signals for encoding evaluation.
    """
    print(f"  Fitting classic SRM for lag {batch.lag_ms}ms...")
    
    # Prepare data for brainiak (needs list of [electrodes, time] numpy arrays)
    train_data_list = [v.train.cpu().numpy().T for v in batch.subject_views.values()]
    test_data_list = [v.test.cpu().numpy().T for v in batch.subject_views.values()]

    # Fit SRM on training data
    srm = brainiak_srm.SRM(n_iter=20, features=k)
    srm.fit(train_data_list)

    # Transform data to shared space
    shared_train = srm.transform(train_data_list)
    shared_test = srm.transform(test_data_list)

    # Prepare word embeddings
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    results = {}

    # Reconstruct and run encoding for each subject
    for i, s_id in enumerate(batch.subjects):
        w_subject = srm.w_[i]
        Y_train_recon = (w_subject @ shared_train[i]).T
        Y_test_recon = (w_subject @ shared_test[i]).T
        results[s_id] = run_encoding_on_data(Y_train_recon, Y_test_recon, X_train_p, X_test_p)
        
    return results


# --- Task 4.2: New plotting function ---
def plot_subject_results(subject_id, lags_list, all_original, all_srm, all_vae, elec_num_dict, plots_folder, plot_format, plot_dpi):
    """
    Creates a plot for a specific subject showing encoding performance across lags
    for all three methods: Original, Classic SRM, and SRM-VAE.
    Saves the plot to the specified folder instead of displaying it.
    """
    # Extract results for the specific subject
    original_r = [res[subject_id] for res in all_original]
    srm_r = [res[subject_id] for res in all_srm]
    vae_r = [res[subject_id] for res in all_vae]
    
    num_electrodes = elec_num_dict.get(subject_id, 'N/A')

    plt.figure(figsize=(5, 4))
    plt.plot(lags_list, original_r, label='Original', color='steelblue', linewidth=3)
    plt.plot(lags_list, srm_r, label='SRM (Classic)', color='darkorange', linewidth=3)
    plt.plot(lags_list, vae_r, label='SRM-VAE', color='green', linewidth=3)
    
    plt.axvline(0, ls='--', color='grey', alpha=0.7)
    plt.xlabel("lags (ms)")
    plt.ylabel("Encoding Performance (r)")
    plt.title(f"Encoding S{subject_id} ({num_electrodes} electrodes)")
    plt.legend()
    plt.ylim(bottom=0)
    plt.grid(True, linestyle=':', alpha=0.6)
    plt.tight_layout()
    
    # Save plot instead of showing it
    plot_filename = f"subject_{subject_id}_encoding.{plot_format}"
    plot_path = os.path.join(plots_folder, plot_filename)
    plt.savefig(plot_path, dpi=plot_dpi, bbox_inches='tight')
    plt.close()  # Close the figure to free memory
    
    print(f"  Saved plot for Subject {subject_id} to: {plot_path}")


# --- Main Execution Block ---
if __name__ == '__main__':
    set_global_seed(SEED)
    
    # Load data
    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
        print(f"Data loaded successfully. Y_data shape: {Y_data.shape}")
    except Exception as e:
        print(f"[ERROR] Failed to load data from {DATA_PATH}: {e}")
        exit()

    # Create subject list and electrode number dictionary
    subjects_list = list(range(1, len(elec_num) + 1))
    elec_num_dict = {s_id: num for s_id, num in zip(subjects_list, elec_num)}

    # Data structures to store results for all three methods
    all_original_results, all_srm_results, all_vae_results = [], [], []

    # Main loop over lags
    for lag_ms in LAG_LIST:
        print(f"\nProcessing Lag: {lag_ms}ms")
        
        # Prepare batch for current lag
        batch = build_lag_batch_from_loaded(Y_data, elec_num, X, lags, lag_ms, TRAIN_RATIO)
        
        # 1. Original encoding (baseline)
        original_results = calculate_original_encoding(batch, PCA_DIM, SEED)
        all_original_results.append(original_results)
        print(f"  > Original Avg r: {np.nanmean(list(original_results.values())):.4f}")

        # 2. Classic SRM encoding
        srm_results = calculate_reconstructed_encoding_srm(batch, SRM_K, PCA_DIM, SEED)
        all_srm_results.append(srm_results)
        print(f"  > Classic SRM Avg r: {np.nanmean(list(srm_results.values())):.4f}")

        # 3. SRM-VAE encoding
        vae_results = calculate_reconstructed_encoding_vae(batch, PCA_DIM, SEED)
        all_vae_results.append(vae_results)
        print(f"  > SRM-VAE Avg r: {np.nanmean(list(vae_results.values())):.4f}")

    print("\n--- Analysis Complete ---")
    print("Generating plots for each subject...")

    # Ensure plots folder exists
    plots_folder = ensure_plots_folder(PLOTS_FOLDER)

    # Generate a plot for each subject
    for s_id in subjects_list:
        plot_subject_results(
            s_id, LAG_LIST, all_original_results, all_srm_results, all_vae_results, 
            elec_num_dict, plots_folder, PLOT_FORMAT, PLOT_DPI
        )
    
    print(f"\nAll plots saved to: {plots_folder}")
    print("Analysis and plotting complete!") 
********************************************************************************

File: .\srm_vs_vae_shared_encoding.py
==================================================
# srm_vs_vae_shared_encoding.py
# Single-file comparison: classic SRM vs SRM-VAE
# - No CLI, no folds. Train/test split by time.
# - Evaluates a list of lags (ms) and plots shared-space encoding curves.

# ========= CONFIG (edit here) =========
DATA_PATH   = "./all_data.pkl"   # path to your all_data.pkl
SEED        = 1234               # random seed
TRAIN_RATIO = 0.8                # first 80% train, last 20% test
LAG_LIST    = [-2000, -1000, -500, 0, 100, 200, 300, 500, 1000, 1500, 1800]

 
SRM_K       = 5               
VAE_K       = 5                  

# Training / eval hyperparams
VAE_EPOCHS  = 1
VAE_LR      = 5e-3
VAE_BETA    = 0.5
PCA_DIM     = 50                  

# Plotting
YLIM        = (0.0, 0.40)
FIGSIZE     = (4.8, 3.5)
SAVE_PNG    = None              
# =====================================

import os
import sys
import math
import pickle
import random
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import matplotlib.pyplot as plt

# --- Torch
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
except Exception:
    print("ERROR: PyTorch not found. Install with: pip install torch")
    raise

# --- SciKit
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression

# --- BrainIAK SRM
try:
    from brainiak.funcalign import srm as brainiak_srm
except Exception:
    print("ERROR: BrainIAK not found. Install with: pip install brainiak")
    raise


# -----------------------------
# Reproducibility utilities
# -----------------------------
def set_global_seed(seed: int = 1234, deterministic: bool = True) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# -----------------------------
# Data structures
# -----------------------------
@dataclass
class SubjectView:
    """Time × Electrodes for one subject, already train/test split & normalized."""
    train: torch.Tensor  # [T_train, E_i]
    test:  torch.Tensor  # [T_test , E_i]
    mask_train: Optional[torch.Tensor] = None  # [E_i] (optional)
    mask_test:  Optional[torch.Tensor] = None  # [E_i] (optional)

@dataclass
class LagBatch:
    """Container for a single lag across all subjects and a simple time split."""
    lag_ms: int
    latent_dim: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor               # [T_train, D_emb]
    X_test:  torch.Tensor               # [T_test , D_emb]
    train_index: np.ndarray
    test_index:  np.ndarray
    elec_num: Dict[int, int]


# -----------------------------
# I/O and preprocessing
# -----------------------------

def load_all_data(pkl_path: str):
    """
    Expected keys in the pkl:
      - 'electrode_data': shape [S, L, T, Emax]
      - 'electrode_number': length S
      - 'word_embeddings': shape [T, D_emb]
      - 'lags': length L (ms)
    """
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])            # [S, L, T, Emax]
    elec_num = np.asarray(obj["electrode_number"], int)   # [S]
    X = np.asarray(obj["word_embeddings"])                # [T, D_emb]
    lags = np.asarray(obj["lags"]).reshape(-1)            # [L]
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    diffs = np.abs(lags_ms - target_ms)
    return int(np.argmin(diffs))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)  # ensure at least 1 test
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)


# -----------------------------
# Build a lag batch (from loaded arrays)
# -----------------------------

def build_lag_batch_from_loaded(
    Y_data: np.ndarray,
    elec_num: np.ndarray,
    X: np.ndarray,
    lags: np.ndarray,
    lag_ms: int,
    latent_dim: int,
    train_ratio: float,
) -> LagBatch:
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_index, test_index = time_split_indices(T, train_ratio)

    # Embeddings: PCA->L2 will be applied later, but we center here with train mean only.
    X_train = X[train_index, :]
    X_test  = X[test_index, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)

    subjects = list(range(1, S + 1))
    subject_views: Dict[int, SubjectView] = {}
    per_sub_elec: Dict[int, int] = {}

    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]   # [T, E_i]
        tr = mat[train_index, :]
        te = mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        mask = np.ones((e_i,), dtype=bool)

        subject_views[subjects[s]] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float(),
            mask_train=torch.from_numpy(mask),
            mask_test=torch.from_numpy(mask),
        )
        per_sub_elec[subjects[s]] = e_i

    return LagBatch(
        lag_ms=chosen_ms,
        latent_dim=latent_dim,
        subjects=subjects,
        subject_views=subject_views,
        X_train=torch.from_numpy(X_train).float(),
        X_test=torch.from_numpy(X_test).float(),
        train_index=train_index,
        test_index=test_index,
        elec_num=per_sub_elec,
    )


# -----------------------------
# SRM-VAE model
# -----------------------------
class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Identity()

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        # Simple averaging of means (like SRM) instead of precision-weighted aggregation
        mu = torch.stack(mu_list, dim=0).mean(dim=0)
        # Average the logvars as well for consistency
        logvar = torch.stack(logvar_list, dim=0).mean(dim=0)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
     
        ortho_pen = torch.tensor(0.0, device=z.device)
        for dec in self.decoders.values():
            W = dec.lin.weight  # [E_i, k]
            G = W.T @ W
            I = torch.eye(G.shape[0], device=G.device)
            ortho_pen = ortho_pen + torch.norm(G - I, p='fro')**2
        
        loss = recon_loss + beta * kl + 1e-3 * ortho_pen  # 
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}


# -----------------------------
# Training (VAE)
# -----------------------------

def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)
        if sv.mask_train is not None: sv.mask_train = sv.mask_train.to(dev)
        if sv.mask_test  is not None: sv.mask_test  = sv.mask_test.to(dev)

    model = SRMVAE(batch.elec_num, k=batch.latent_dim).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None

    for ep in range(1, epochs + 1):
        model.train()
        beta_ep = beta * min(1.0, ep / 500)  # warm-up over ~50 epochs
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta_ep)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}")

    if best_state is not None:
        model.load_state_dict(best_state)
    return model


# -----------------------------
# Shared-space encoding metrics (both methods)
# -----------------------------

def _prep_embeddings(X_train: np.ndarray, X_test: np.ndarray, pca_dim: int, seed: int):
    """PCA->L2 normalize rows. Fit PCA on train only."""
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p  = pca.transform(X_test)
    X_train_p = normalize(X_train_p, axis=1)
    X_test_p  = normalize(X_test_p, axis=1)
    return X_train_p, X_test_p, float(pca.explained_variance_ratio_.sum())

def _colwise_pearsonr(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

def shared_encoding_vae(batch: LagBatch, k: int, pca_dim: int, seed: int) -> Tuple[float, np.ndarray]:
    """Return (mean r over dims, r per dim) for SRM-VAE at this lag."""
    dev = torch_device()
    vae = train_srmvae_on_batch(batch, epochs=VAE_EPOCHS, lr=VAE_LR, beta=VAE_BETA, verbose=True)
    vae.eval()

    # Infer shared z (μ)
    z_tr, _, _ = vae.infer_z(batch.subject_views, split="train", use_mu=True)
    z_te, _, _ = vae.infer_z(batch.subject_views, split="test",  use_mu=True)
    z_train = z_tr.cpu().numpy()  # [T_train, k]
    z_test  = z_te.cpu().numpy()  # [T_test,  k]

    # Standardize z per dim
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    z_train_std = z_scaler.fit_transform(z_train)
    z_test_std  = z_scaler.transform(z_test)

    # Embeddings -> PCA+L2
    X_train_raw = batch.X_train.cpu().numpy()
    X_test_raw  = batch.X_test.cpu().numpy()
    X_train_p, X_test_p, _ = _prep_embeddings(X_train_raw, X_test_raw, pca_dim=pca_dim, seed=seed)

    # Linear map X -> z (multi-output regression)
    reg = LinearRegression()
    reg.fit(X_train_p, z_train_std)
    z_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(z_test_std, z_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return r_mean, r_dims


def shared_encoding_srm(Y_data: np.ndarray, elec_num: np.ndarray, X: np.ndarray,
                        lags: np.ndarray, lag_ms: int, train_ratio: float,
                        k: int, pca_dim: int, seed: int) -> Tuple[int, float, np.ndarray]:
    """
    Classic SRM baseline (brainiak):
    - Builds time-based train/test splits
    - Fits SRM on train data per subject
    - Averages shared time series across subjects
    - Regresses embeddings → shared dims and returns correlation per dim.
    Returns (chosen_lag_ms, mean r, r per dim)
    """
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_idx, test_idx = time_split_indices(T, train_ratio)

    # Prepare per-subject matrices
    train_data, test_data = [], []
    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]  # [T, E_i]
        tr = mat[train_idx, :]
        te = mat[test_idx, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        train_data.append(tr_z.T)  # [E_i, T_train]
        test_data.append(te_z.T)   # [E_i, T_test]

    # Fit SRM
    srm = brainiak_srm.SRM(n_iter=100, features=k)
    srm.fit(train_data)

    shared_train_list = srm.transform(train_data)
    shared_test_list  = srm.transform(test_data)

    s_train = np.mean(np.stack(shared_train_list, axis=0), axis=0).T  # [T_train, k]
    s_test  = np.mean(np.stack(shared_test_list,  axis=0), axis=0).T  # [T_test , k]

    # Standardize dims
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    s_train_std = z_scaler.fit_transform(s_train)
    s_test_std  = z_scaler.transform(s_test)

    # Embeddings -> PCA+L2
    X_train = X[train_idx, :]
    X_test  = X[test_idx, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)
    X_train_p, X_test_p, _ = _prep_embeddings(X_train, X_test, pca_dim=pca_dim, seed=seed)

    reg = LinearRegression()
    reg.fit(X_train_p, s_train_std)
    s_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(s_test_std, s_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return chosen_ms, r_mean, r_dims


# -----------------------------
# Multi-lag sweep + plot
# -----------------------------

def sweep_and_plot(Y_data, elec_num, X, lags, lag_list, srm_k, vae_k,
                   train_ratio, pca_dim, seed, ylim, figsize, save_png):
    dev = torch_device()
    print(f"[INFO] torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, device: {dev}")
    print(f"[DATA] Y={Y_data.shape}, X={X.shape}, lags_count={len(lags)}")
    print(f"[CONF] TRAIN_RATIO={train_ratio}, SRM_K={srm_k}, VAE_K={vae_k}, PCA_DIM={pca_dim}")

    srm_means, srm_sems, lag_actual_srm = [], [], []
    vae_means, vae_sems, lag_actual_vae = [], [], []

    for req in lag_list:
        # SRM baseline
        chosen_ms, srm_mean, srm_r_dims = shared_encoding_srm(
            Y_data, elec_num, X, lags,
            lag_ms=req, train_ratio=train_ratio,
            k=srm_k, pca_dim=pca_dim, seed=seed
        )
        srm_means.append(srm_mean)
        srm_sems.append(np.nanstd(srm_r_dims, ddof=1) / np.sqrt(len(srm_r_dims)))
        lag_actual_srm.append(chosen_ms)
        print(f"[SRM] lag req={req} -> chosen={chosen_ms} | r_mean={srm_mean:.3f}")

        # VAE baseline
        batch = build_lag_batch_from_loaded(
            Y_data, elec_num, X, lags,
            lag_ms=req, latent_dim=vae_k, train_ratio=train_ratio
        )
        vae_mean, vae_r_dims = shared_encoding_vae(batch, k=vae_k, pca_dim=pca_dim, seed=seed)
        vae_means.append(vae_mean)
        vae_sems.append(np.nanstd(vae_r_dims, ddof=1) / np.sqrt(len(vae_r_dims)))
        lag_actual_vae.append(batch.lag_ms)
        print(f"[VAE] lag req={req} -> chosen={batch.lag_ms} | r_mean={vae_mean:.3f}")

    x = np.asarray(lag_list, dtype=int)
    srm_means = np.asarray(srm_means)
    srm_sems  = np.asarray(srm_sems)
    vae_means = np.asarray(vae_means)
    vae_sems  = np.asarray(vae_sems)

    # Plot
    plt.figure(figsize=figsize)
    plt.fill_between(x, srm_means - srm_sems, srm_means + srm_sems, alpha=0.2, color='darkorange')
    plt.plot(x, srm_means, linewidth=3.5, label='SRM', color='darkorange')

    plt.fill_between(x, vae_means - vae_sems, vae_means + vae_sems, alpha=0.2, color='royalblue')
    plt.plot(x, vae_means, linewidth=3.5, label='VAE', color='royalblue')

    plt.axvline(0, ls='dashed', c='k', alpha=0.3)
    plt.ylim(ylim)
    plt.xlabel('lags (ms)')
    plt.ylabel('Encoding Performance (r)')
    plt.title('Shared Space Encoding')
    plt.legend()
    plt.tight_layout()

    if save_png:
        plt.savefig(save_png, dpi=150)
        print(f"[PLOT] Saved to {save_png}")
    plt.show()

    return {
        'x_requested': x,
        'srm': {'means': srm_means, 'sems': srm_sems, 'chosen_lags': lag_actual_srm},
        'vae': {'means': vae_means, 'sems': vae_sems, 'chosen_lags': lag_actual_vae},
    }


# -----------------------------
# Main
# -----------------------------

if __name__ == '__main__':
    set_global_seed(SEED, deterministic=True)
    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
    except Exception as e:
        print(f"[ERROR] Failed to load data: {e}")
        sys.exit(1)

    sweep_and_plot(
        Y_data=Y_data,
        elec_num=elec_num,
        X=X,
        lags=lags,
        lag_list=LAG_LIST,
        srm_k=SRM_K,
        vae_k=VAE_K,
        train_ratio=TRAIN_RATIO,
        pca_dim=PCA_DIM,
        seed=SEED,
        ylim=YLIM,
        figsize=FIGSIZE,
        save_png=SAVE_PNG,
    )

********************************************************************************

File: .\vae_srm_one_lag.py
==================================================
# vae_single_lag.py
# Train & evaluate the SRM-VAE on a SINGLE lag (default 20 ms).
# - No CLI, no folds. Simple time split by TRAIN_RATIO.
# - Prints reconstruction MSE per subject and shared-space encoding r.

# ========= CONFIG (edit here) =========
DATA_PATH   = "./all_data.pkl"   # path to your all_data.pkl
SEED        = 1234               # random seed
TRAIN_RATIO = 0.8                # first 80% train, last 20% test
LAG_MS      = 20                 # target lag (ms); uses closest available lag in the file

LATENT_K    = 5                # VAE shared latent dims
EPOCHS      = 400000
LR          =5e-4
BETA        = 2               # β-VAE weight

# For shared-space encoding evaluation (X -> z)
PCA_DIM     = 50                 # reduce embeddings to 50D then L2 row-normalize
VERBOSE     = True
SAVE_NPZ    = None               # e.g., "vae_single_lag_results.npz" or None
# =====================================

import os
import sys
import math
import pickle
import random
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np

# Torch
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
except Exception:
    print("ERROR: PyTorch not found. Install with: pip install torch")
    raise

# SciKit
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression


# -----------------------------
# Reproducibility utilities
# -----------------------------
def set_global_seed(seed: int = 1234, deterministic: bool = True) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# -----------------------------
# Data structures
# -----------------------------
@dataclass
class SubjectView:
    """Time × Electrodes for one subject, already train/test split & normalized."""
    train: torch.Tensor  # [T_train, E_i]
    test:  torch.Tensor  # [T_test , E_i]
    mask_train: Optional[torch.Tensor] = None  # [E_i] (optional)
    mask_test:  Optional[torch.Tensor] = None  # [E_i] (optional)

@dataclass
class LagBatch:
    """Container for a single lag across all subjects and a simple time split."""
    lag_ms: int
    latent_dim: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor               # [T_train, D_emb]
    X_test:  torch.Tensor               # [T_test , D_emb]
    train_index: np.ndarray
    test_index:  np.ndarray
    elec_num: Dict[int, int]


# -----------------------------
# I/O and preprocessing
# -----------------------------
def load_all_data(pkl_path: str):
    """
    Expected keys:
      - 'electrode_data': [S, L, T, Emax]
      - 'electrode_number': [S]
      - 'word_embeddings': [T, D_emb]
      - 'lags': [L] (ms)
    """
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])            # [S, L, T, Emax]
    elec_num = np.asarray(obj["electrode_number"], int)   # [S]
    X = np.asarray(obj["word_embeddings"])                # [T, D_emb]
    lags = np.asarray(obj["lags"]).reshape(-1)            # [L]
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    diffs = np.abs(lags_ms - target_ms)
    return int(np.argmin(diffs))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)  # ensure at least 1 test
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)


def build_lag_batch_from_loaded(
    Y_data: np.ndarray,
    elec_num: np.ndarray,
    X: np.ndarray,
    lags: np.ndarray,
    lag_ms: int,
    latent_dim: int,
    train_ratio: float,
) -> LagBatch:
    """Build a single-lag batch with z-scoring per subject and centered embeddings."""
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_index, test_index = time_split_indices(T, train_ratio)

    # Embeddings: center by train mean only
    X_train = X[train_index, :]
    X_test  = X[test_index, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)

    subjects = list(range(1, S + 1))
    subject_views: Dict[int, SubjectView] = {}
    per_sub_elec: Dict[int, int] = {}

    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]   # [T, E_i]
        tr = mat[train_index, :]
        te = mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        mask = np.ones((e_i,), dtype=bool)

        subject_views[subjects[s]] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float(),
            mask_train=torch.from_numpy(mask),
            mask_test=torch.from_numpy(mask),
        )
        per_sub_elec[subjects[s]] = e_i

    return LagBatch(
        lag_ms=chosen_ms,
        latent_dim=latent_dim,
        subjects=subjects,
        subject_views=subject_views,
        X_train=torch.from_numpy(X_train).float(),
        X_test=torch.from_numpy(X_test).float(),
        train_index=train_index,
        test_index=test_index,
        elec_num=per_sub_elec,
    )


# -----------------------------
# SRM-VAE model
# -----------------------------
class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Sequential(nn.Linear(k, k), nn.ReLU(), nn.Linear(k, k))
        for m in self.core:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        precisions = [torch.exp(-lv) for lv in logvar_list]
        prec_sum = torch.stack(precisions, dim=0).sum(dim=0)
        weighted_mu = torch.stack([m * p for m, p in zip(mu_list, precisions)], dim=0).sum(dim=0)
        var = 1.0 / (prec_sum + 1e-8)
        mu = var * weighted_mu
        logvar = torch.log(var + 1e-8)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)  # [T,E_i]
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        # tensor (not python float) for stability
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)           # [T,E_i]
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        loss = recon_loss + beta * kl
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}


# -----------------------------
# Training
# -----------------------------
def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)
        if sv.mask_train is not None: sv.mask_train = sv.mask_train.to(dev)
        if sv.mask_test  is not None: sv.mask_test  = sv.mask_test.to(dev)

    model = SRMVAE(batch.elec_num, k=batch.latent_dim).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None
    patience = math.inf
    no_imp = 0

    for ep in range(1, epochs + 1):
        model.train()
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
            no_imp = 0
        else:
            no_imp += 1

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}  no_imp={no_imp}")

        if no_imp >= patience:
            if verbose:
                print(f"[early stop] best_loss={best_loss:.5f} at ep≈{ep-no_imp}")
            break

    if best_state is not None:
        model.load_state_dict(best_state)
    return model


# -----------------------------
# Evaluation helpers
# -----------------------------
def _prep_embeddings(X_train: np.ndarray, X_test: np.ndarray, pca_dim: int, seed: int):
    """PCA -> L2 normalize rows. Fit PCA on train only."""
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p  = pca.transform(X_test)
    X_train_p = normalize(X_train_p, axis=1)
    X_test_p  = normalize(X_test_p, axis=1)
    return X_train_p, X_test_p, float(pca.explained_variance_ratio_.sum())

def _colwise_pearsonr(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

def eval_encoding_PCA_Ridge(batch: LagBatch, vae: SRMVAE, pca_dim: int = 50, seed: int = SEED):
    """Shared-space encoding: regress PCA+L2(X) -> standardized μ(z) on train; eval on test."""
    dev = torch_device()
    vae.eval()
    with torch.no_grad():
        z_tr, _, _ = vae.infer_z(batch.subject_views, split="train", use_mu=True)
        z_te, _, _ = vae.infer_z(batch.subject_views, split="test",  use_mu=True)
    z_train = z_tr.cpu().numpy()  # [T_train, k]
    z_test  = z_te.cpu().numpy()  # [T_test,  k]

    # Standardize z (train stats only)
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    z_train_std = z_scaler.fit_transform(z_train)
    z_test_std  = z_scaler.transform(z_test)

    # Embeddings: PCA(pca_dim) + L2 per row
    X_train_raw = batch.X_train.cpu().numpy()
    X_test_raw  = batch.X_test.cpu().numpy()
    X_train_p, X_test_p, pca_var = _prep_embeddings(X_train_raw, X_test_raw, pca_dim=pca_dim, seed=seed)

    # Linear regression X -> z
    reg = LinearRegression()
    reg.fit(X_train_p, z_train_std)
    z_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(z_test_std, z_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return {
        "r_z_mean": r_mean,
        "r_z_dims": r_dims,
        "pca_explained": pca_var,
    }


# -----------------------------
# Main
# -----------------------------
if __name__ == "__main__":
    set_global_seed(SEED, deterministic=True)
    dev = torch_device()
    print(f"[INFO] torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, device: {dev}")
    print(f"[INFO] DATA_PATH={DATA_PATH} | LATENT_K={LATENT_K} | TRAIN_RATIO={TRAIN_RATIO} | LAG_MS(target)={LAG_MS}")

    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
    except Exception as e:
        print(f"[ERROR] Failed to load data: {e}")
        sys.exit(1)

    # Build single-lag batch (closest to LAG_MS)
    batch = build_lag_batch_from_loaded(
        Y_data=Y_data,
        elec_num=elec_num,
        X=X,
        lags=lags,
        lag_ms=LAG_MS,
        latent_dim=LATENT_K,
        train_ratio=TRAIN_RATIO,
    )
    print(f"[OK] using lag_ms={batch.lag_ms} (closest to {LAG_MS})")
    s1 = batch.subjects[0]
    print(f"     S{s1} train shape: {tuple(batch.subject_views[s1].train.shape)}")
    print(f"     X_train: {tuple(batch.X_train.shape)}  X_test: {tuple(batch.X_test.shape)}")

    # Train VAE
    print(f"[TRAIN] SRM-VAE on lag={batch.lag_ms} ms, k={batch.latent_dim}")
    vae = train_srmvae_on_batch(batch, epochs=EPOCHS, lr=LR, beta=BETA, verbose=VERBOSE)

    # Inference & quick reconstruction MSEs on test
    vae.eval()
    with torch.no_grad():
        z_te, _, _ = vae.infer_z(batch.subject_views, split="test", use_mu=True)
        recons_test = vae.reconstruct_subjects(z_te.to(dev))
        for sid in batch.subjects:
            x_true = batch.subject_views[sid].test.to(dev)
            x_hat  = recons_test[sid]
            mse = F.mse_loss(x_hat, x_true).item()
            print(f"[TEST] Subject {sid}: recon MSE = {mse:.6f}")

    # Shared-space encoding eval (X -> z)
    print(f"[EVAL] PCA({PCA_DIM})+Linear encoding to z")
    enc = eval_encoding_PCA_Ridge(batch, vae, pca_dim=PCA_DIM, seed=SEED)
    print(f"[ENC] Shared-space r (mean over k={LATENT_K}): {enc['r_z_mean']:.4f}  | PCA var={enc['pca_explained']:.2f}")

    if SAVE_NPZ:
        np.savez(
            SAVE_NPZ,
            lag_ms=batch.lag_ms,
            r_z_mean=enc["r_z_mean"],
            r_z_dims=enc["r_z_dims"],
            latent_k=LATENT_K,
            train_ratio=TRAIN_RATIO,
            pca_dim=PCA_DIM,
        )
        print(f"[SAVE] Wrote metrics to {SAVE_NPZ}")

********************************************************************************

File: .\vae_vs_srm_generalization.py
==================================================
# vae_vs_srm_generalization.py
# --- CONFIG (editable) ---
DATA_PATH   = "./all_data.pkl"
SEED        = 1234
TRAIN_RATIO = 0.8
LAG_LIST    = [-500, 0, 200, 500]  # Lags to test (ms)
PCA_DIM     = 50

# Directory to save plots
OUTPUT_DIR  = "shared_space_plots"

# --- Imports ---
import os, pickle, random
from typing import Dict, List
from dataclasses import dataclass

import numpy as np
import torch, torch.nn as nn, torch.nn.functional as F
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from brainiak.funcalign import srm as brainiak_srm

# Create output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Shared dimension and VAE hyper-parameters
SHARED_K   = 5
VAE_EPOCHS = 500
VAE_LR     = 1e-3
VAE_BETA   = 0.1

# ----------------- helpers -----------------

def set_global_seed(seed=1234):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

@dataclass
class SubjectView:
    train: torch.Tensor
    test:  torch.Tensor
    elec_num: int = 0

@dataclass
class LagBatch:
    lag_ms: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor
    X_test:  torch.Tensor
    elec_num: Dict[int,int]

# ------------- IO -------------

def load_all_data(path):
    with open(path, "rb") as f:
        obj = pickle.load(f)
    return (np.asarray(obj["electrode_data"]),
            np.asarray(obj["electrode_number"], int),
            np.asarray(obj["word_embeddings"]),
            np.asarray(obj["lags"]).reshape(-1))

# ------------- preprocessing -------------

def _prep_embeddings(Xtr, Xte, pca_dim, seed):
    pca = PCA(n_components=pca_dim, random_state=seed)
    Xtr_p = pca.fit_transform(Xtr)
    Xte_p = pca.transform(Xte)
    return normalize(Xtr_p, axis=1), normalize(Xte_p, axis=1)

def _zscore_train_apply(tr, te):
    mu = tr.mean(0, keepdims=True); sd = tr.std(0, keepdims=True)+1e-8
    return (tr-mu)/sd, (te-mu)/sd

def choose_lag_index(lags_ms, target_ms):
    return int(np.argmin(np.abs(lags_ms-target_ms)))

def time_split_indices(T, ratio):
    n = min(max(1,int(round(T*ratio))), T-1)
    return np.arange(n), np.arange(n, T)

# ------------- VAE-SRM model -------------
class Enc(nn.Module):
    def __init__(self,e_i,k): super().__init__(); self.lin=nn.Linear(e_i,2*k); nn.init.xavier_uniform_(self.lin.weight)
    def forward(self,x): return torch.chunk(self.lin(x),2,-1)
class Dec(nn.Module):
    def __init__(self,k,e_i): super().__init__(); self.lin=nn.Linear(k,e_i,bias=False); nn.init.xavier_uniform_(self.lin.weight)
    def forward(self,z): return self.lin(z)
class SRMVAE(nn.Module):
    def __init__(self,elec_num:Dict[int,int],k:int):
        super().__init__()
        self.encoders=nn.ModuleDict({str(s):Enc(e,k) for s,e in elec_num.items()})
        self.decoders=nn.ModuleDict({str(s):Dec(k,e) for s,e in elec_num.items()})
    @staticmethod
    def _agg(mu_list,lv_list):
        prec=[torch.exp(-lv) for lv in lv_list]; tot=torch.stack(prec,0).sum(0)+1e-8
        mu=torch.stack([m*p for m,p in zip(mu_list,prec)],0).sum(0)/tot
        return mu, -torch.log(tot)
    def encode_group(self,views,split):
        mus,lvs=[],[]
        for sid_str,enc in self.encoders.items():
            sid=int(sid_str)
            if sid in views:
                mu,lv=enc(getattr(views[sid],split))
                mus.append(mu); lvs.append(lv)
        return self._agg(mus,lvs)
    def forward(self,views,beta):
        mu,lv=self.encode_group(views,"train")
        z=mu+torch.exp(0.5*lv)*torch.randn_like(mu)
        rec=sum(F.mse_loss(self.decoders[sid_str](z), views[int(sid_str)].train)
                for sid_str in self.decoders.keys() if int(sid_str) in views)
        kl=-0.5*torch.mean(1+lv-mu.pow(2)-lv.exp())
        return rec+beta*kl
    @torch.no_grad()
    def infer_z(self,views,split):
        return self.encode_group(views,split)[0]

def train_vae(batch,k,epochs,lr,beta):
    dev=torch_device()
    for v in batch.subject_views.values(): v.train,v.test=v.train.to(dev),v.test.to(dev)
    model=SRMVAE(batch.elec_num,k).to(dev)
    opt=torch.optim.Adam(model.parameters(),lr=lr)
    for _ in range(epochs):
        opt.zero_grad(); loss=model(batch.subject_views,beta); loss.backward(); opt.step()
    return model

# ------------- batch builder -------------

def build_batches(Y,elec,X,lags,lag_ms,ratio,test_sid):
    S,_,T,_=Y.shape
    idx=choose_lag_index(lags,lag_ms)
    tr,te=time_split_indices(T,ratio)
    Xtr,Xte=X[tr],X[te]
    Xtr-=Xtr.mean(0,keepdims=True); Xte-=Xtr.mean(0,keepdims=True)
    train_sids=[s for s in range(1,S+1) if s!=test_sid]
    views,elec_dict={},{}
    for sid in train_sids:
        e=int(elec[sid-1]); mat=Y[sid-1,idx,:,:e]
        tr_z, te_z = _zscore_train_apply(mat[tr], mat[te])
        views[sid] = SubjectView(torch.tensor(tr_z, dtype=torch.float32),
                                 torch.tensor(te_z, dtype=torch.float32))
        elec_dict[sid] = e
    batch = LagBatch(int(lags[idx]),
                     train_sids,
                     views,
                     torch.tensor(Xtr, dtype=torch.float32),
                     torch.tensor(Xte, dtype=torch.float32),
                     elec_dict)
    e_test=int(elec[test_sid-1]); mat_t=Y[test_sid-1,idx,:,:e_test]
    tr_z_t, te_z_t = _zscore_train_apply(mat_t[tr], mat_t[te])
    test_view = SubjectView(torch.tensor(tr_z_t, dtype=torch.float32),
                            torch.tensor(te_z_t, dtype=torch.float32),
                            elec_num=e_test)
    return batch,test_view

# ------------- analyses -------------

def vae_generalization(batch,test_view):
    model=train_vae(batch,SHARED_K,VAE_EPOCHS,VAE_LR,VAE_BETA).eval()
    z_train=model.infer_z(batch.subject_views,"train").cpu().numpy()
    Xtr_p,Xte_p=_prep_embeddings(batch.X_train.numpy(),batch.X_test.numpy(),PCA_DIM,SEED)
    enc=LinearRegression().fit(Xtr_p,z_train)
    z_pred=enc.predict(Xte_p)
    Ytr=test_view.train.numpy(); W,_,_,_=np.linalg.lstsq(Ytr,z_train,rcond=None)
    z_true=test_view.test.numpy() @ W
    vx,vy=z_true-z_true.mean(0), z_pred-z_pred.mean(0)
    r=np.sum(vx*vy,0)/(np.sqrt(np.sum(vx**2,0))*np.sqrt(np.sum(vy**2,0))+1e-8)
    return float(np.nanmean(r))

# Classic SRM generalization with safe device transfers
def srm_generalization(batch, test_view):
    train_data = [v.train.cpu().numpy().T for v in batch.subject_views.values()]
    self_tr = test_view.train.cpu().numpy().T
    self_te = test_view.test.cpu().numpy().T
    srm=brainiak_srm.SRM(n_iter=50,features=SHARED_K); srm.fit(train_data)
    shared_train=srm.s_.T
    Xtr_p,Xte_p=_prep_embeddings(batch.X_train.numpy(),batch.X_test.numpy(),PCA_DIM,SEED)
    enc=LinearRegression().fit(Xtr_p,shared_train)
    z_pred=enc.predict(Xte_p)
    W=self_tr @ shared_train @ np.linalg.inv(shared_train.T @ shared_train)
    z_true=(W.T @ self_te).T
    vx,vy=z_true-z_true.mean(0), z_pred-z_pred.mean(0)
    r=np.sum(vx*vy,0)/(np.sqrt(np.sum(vx**2,0))*np.sqrt(np.sum(vy**2,0))+1e-8)
    return float(np.nanmean(r))

# ------------- main -------------
if __name__=="__main__":
    set_global_seed(SEED)
    Y,elec,X,lags=load_all_data(DATA_PATH)
    subjects=list(range(1,len(elec)+1))
    scores_vae={s:{} for s in subjects}; scores_srm={s:{} for s in subjects}

    for sid in subjects:
        print(f"\n>>> Subject {sid}")
        for lag in LAG_LIST:
            batch,test_view=build_batches(Y,elec,X,lags,lag,TRAIN_RATIO,sid)
            r_vae=vae_generalization(batch,test_view)
            r_srm=srm_generalization(batch,test_view)
            scores_vae[sid][lag]=r_vae; scores_srm[sid][lag]=r_srm
            print(f"  lag {lag:4d} | VAE {r_vae:.3f} | SRM {r_srm:.3f}")

    # ---------- plotting per subject ----------
    for sid in subjects:
        plt.figure(figsize=(5.2,3.6))
        lags=LAG_LIST
        plt.plot(lags,[scores_vae[sid][l] for l in lags],'-o',label='VAE',color='dodgerblue')
        plt.plot(lags,[scores_srm[sid][l] for l in lags],'-o',label='SRM',color='darkorange')
        plt.axvline(0,ls="--",color='grey',alpha=0.5)
        plt.title(f'Subject {sid}'); plt.xlabel('lag (ms)'); plt.ylabel('generalization r')
        plt.legend(); plt.tight_layout();
        plt.savefig(f"{OUTPUT_DIR}/subject_{sid}_vae_vs_srm.png", dpi=300)
        plt.close()

    # ---------- combined plot ----------
    colors=plt.cm.tab10(np.linspace(0,1,len(subjects)))
    plt.figure(figsize=(6,4))
    for i,sid in enumerate(subjects):
        plt.plot(LAG_LIST,[scores_vae[sid][l] for l in LAG_LIST],color=colors[i],lw=1.8,label=f'S{sid}')
    plt.axvline(0,ls='--',color='grey',alpha=0.6); plt.title('All subjects – VAE'); plt.xlabel('lag (ms)'); plt.ylabel('r'); plt.legend(ncol=2,fontsize=8); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/all_subjects_vae_only.png", dpi=300)
    plt.close()

    # ---------- averages ----------
    def mean_sem(score_dict):
        mean,sem=[],[]
        for l in LAG_LIST:
            arr=np.array([score_dict[sid][l] for sid in subjects])
            mean.append(arr.mean()); sem.append(arr.std(ddof=1)/np.sqrt(len(arr)))
        return np.array(mean),np.array(sem)
    m_vae,se_vae=mean_sem(scores_vae); m_srm,se_srm=mean_sem(scores_srm)
    plt.figure(figsize=(6,4))
    plt.plot(LAG_LIST,m_vae,color='dodgerblue',lw=3,label='VAE'); plt.fill_between(LAG_LIST,m_vae-se_vae,m_vae+se_vae,color='dodgerblue',alpha=0.25)
    plt.plot(LAG_LIST,m_srm,color='darkorange',lw=3,label='SRM'); plt.fill_between(LAG_LIST,m_srm-se_srm,m_srm+se_srm,color='darkorange',alpha=0.25)
    plt.axvline(0,ls='--',color='grey',alpha=0.6)
    plt.xlabel('lag (ms)'); plt.ylabel('mean r ± sem'); plt.title('VAE vs classic SRM – average'); plt.legend(); plt.grid(True,linestyle=':',alpha=0.5); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/averages_vae_vs_srm.png", dpi=300)
    plt.close()

    # ---------- combined subjects plot ----------
    fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
    colors = plt.cm.viridis(np.linspace(0, 1, len(subjects)))
    # VAE Plot
    axes[0].set_title('All Subjects: VAE Generalization')
    for i, sid in enumerate(subjects):
        lags_sorted = sorted(scores_vae[sid].keys())
        scores_sorted = [scores_vae[sid][lag] for lag in lags_sorted]
        axes[0].plot(lags_sorted, scores_sorted, color=colors[i], lw=2, label=f'Subject {sid}')
    # SRM Plot
    axes[1].set_title('All Subjects: Classic SRM Generalization')
    for i, sid in enumerate(subjects):
        lags_sorted = sorted(scores_srm[sid].keys())
        scores_sorted = [scores_srm[sid][lag] for lag in lags_sorted]
        axes[1].plot(lags_sorted, scores_sorted, color=colors[i], lw=2, label=f'Subject {sid}')
    for ax in axes:
        ax.axvline(0, ls="--", color="grey", alpha=0.6)
        ax.set_xlabel('lag (ms)'); ax.grid(True, linestyle=":", alpha=0.5); ax.legend()
    axes[0].set_ylabel('Generalization Performance (r)'); plt.tight_layout()
    fig.savefig(f"{OUTPUT_DIR}/all_subjects_vae_vs_srm.png", dpi=300)
    plt.close(fig)

    # Create the plot
    plt.figure(figsize=(7, 5))
    plt.plot(LAG_LIST, m_vae, color="dodgerblue", lw=3, label="VAE Generalization (Avg)")
    plt.fill_between(LAG_LIST, m_vae - se_vae, m_vae + se_vae, color="dodgerblue", alpha=0.2)
    plt.plot(LAG_LIST, m_srm, color="darkorange", lw=3, label="Classic SRM Generalization (Avg)")
    plt.fill_between(LAG_LIST, m_srm - se_srm, m_srm + se_srm, color="darkorange", alpha=0.2)
    plt.axvline(0, ls="--", color="grey", alpha=0.6); plt.xlabel("lag (ms)"); plt.ylabel("Avg. Generalization Performance (r)")
    plt.title("Comparison of Average Generalization Performance"); plt.grid(True, linestyle=":", alpha=0.5)
    plt.legend(); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/average_vae_vs_srm.png", dpi=300)
    plt.close()
********************************************************************************

File: extract_python_files.py
==================================================
import os
import glob

def extract_python_files_to_txt():
    """
    Extract all Python files (excluding notebooks) in the current directory
    and create a TXT file with filename and content separated by asterisks
    """
    
    # Get all Python files in current directory (excluding notebooks)
    python_files = []
    
    # Find all .py files
    py_files = glob.glob("*.py")
    python_files.extend(py_files)
    
    # Find all .py files in subdirectories
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.endswith(".py"):
                full_path = os.path.join(root, file)
                python_files.extend([full_path])
    
    # Remove duplicates and sort
    python_files = sorted(list(set(python_files)))
    
    # Create output file
    output_filename = "python_files_content.txt"
    
    with open(output_filename, 'w', encoding='utf-8') as output_file:
        for i, file_path in enumerate(python_files):
            try:
                # Read file content
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Write filename
                output_file.write(f"File: {file_path}\n")
                output_file.write("=" * 50 + "\n")
                
                # Write content
                output_file.write(content)
                
                # Add separator (except for last file)
                if i < len(python_files) - 1:
                    output_file.write("\n" + "*" * 80 + "\n\n")
                    
            except Exception as e:
                print(f"Error reading {file_path}: {e}")
                output_file.write(f"Error reading file: {e}\n")
                if i < len(python_files) - 1:
                    output_file.write("\n" + "*" * 80 + "\n\n")
    
    print(f"Extracted {len(python_files)} Python files to {output_filename}")
    print("Files processed:")
    for file_path in python_files:
        print(f"  - {file_path}")

if __name__ == "__main__":
    extract_python_files_to_txt() 
********************************************************************************

File: new_script_reconstruction.py
==================================================
# new_script_reconstruction.py
# --- CONFIG (editable) ---
DATA_PATH   = "./all_data.pkl"
SEED        = 1234
TRAIN_RATIO = 0.8
LAG_LIST    =  [-2000, -1000, -500, 0, 100, 200, 300, 500, 1000, 1500, 1800] # Expanded list for better plots
PCA_DIM     = 50

# VAE & SRM Hyperparameters
SRM_K       = 5      # Latent dimension for classic SRM
VAE_K       = 5      # Latent dimension for VAE
VAE_EPOCHS  = 500    # Number of training epochs
VAE_LR      = 1e-3   # Learning rate
VAE_BETA    = 0.1    # Weight of the KL divergence term

# Plotting settings
PLOTS_FOLDER = "./reconstruction_plots"  # Folder to save plots
PLOT_FORMAT = "png"                      # Plot file format (png, pdf, svg)
PLOT_DPI = 150                           # Plot resolution

# --- Imports and Helper Functions (same as original script) ---
import os
import pickle
import random
import math
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression
from brainiak.funcalign import srm as brainiak_srm

# Settings and helper functions copied from original script for standalone execution
def set_global_seed(seed: int = 1234) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

def ensure_plots_folder(folder_path):
    """Create plots folder if it doesn't exist"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        print(f"Created plots folder: {folder_path}")
    else:
        print(f"Using existing plots folder: {folder_path}")
    return folder_path

@dataclass
class SubjectView:
    train: torch.Tensor
    test:  torch.Tensor

@dataclass
class LagBatch:
    lag_ms: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor
    X_test:  torch.Tensor
    elec_num: Dict[int, int]

def load_all_data(pkl_path: str):
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])
    elec_num = np.asarray(obj["electrode_number"], int)
    X = np.asarray(obj["word_embeddings"])
    lags = np.asarray(obj["lags"]).reshape(-1)
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    return int(np.argmin(np.abs(lags_ms - target_ms)))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)

def build_lag_batch_from_loaded(Y_data, elec_num, X, lags, lag_ms, train_ratio):
    S, _, T, _ = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    train_index, test_index = time_split_indices(T, train_ratio)
    
    X_train, X_test = X[train_index, :], X[test_index, :]
    X_train_mean = X_train.mean(axis=0, keepdims=True)
    X_train_np = X_train - X_train_mean
    X_test_np = X_test - X_train_mean
    
    subject_views = {}
    per_sub_elec = {}
    subjects = list(range(1, S + 1))
    
    for s_idx, s_id in enumerate(subjects):
        e_i = int(elec_num[s_idx])
        mat = Y_data[s_idx, lag_idx, :, :e_i]
        tr, te = mat[train_index, :], mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        subject_views[s_id] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float()
        )
        per_sub_elec[s_id] = e_i
        
    return LagBatch(
        lag_ms=int(lags[lag_idx]), subjects=subjects, subject_views=subject_views,
        X_train=torch.from_numpy(X_train_np).float(),
        X_test=torch.from_numpy(X_test_np).float(),
        elec_num=per_sub_elec
    )

def _prep_embeddings(X_train, X_test, pca_dim, seed):
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p = pca.transform(X_test)
    return normalize(X_train_p, axis=1), normalize(X_test_p, axis=1)

def _colwise_pearsonr(y_true, y_pred, eps=1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

# --- Helper function for encoding calculation ---
def run_encoding_on_data(Y_train, Y_test, X_train_p, X_test_p):
    """Helper function to run encoding on data and return average correlation"""
    corrs = []
    num_electrodes = Y_train.shape[1]
    for elec_idx in range(num_electrodes):
        reg = LinearRegression().fit(X_train_p, Y_train[:, elec_idx])
        pred = reg.predict(X_test_p)
        corr = np.corrcoef(Y_test[:, elec_idx], pred)[0, 1]
        if not np.isnan(corr):
            corrs.append(corr)
    return np.mean(corrs) if corrs else np.nan

# --- SRM-VAE Model and Functions ---

class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
        
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Identity()

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        # Simple averaging of means (like SRM) instead of precision-weighted aggregation
        mu = torch.stack(mu_list, dim=0).mean(dim=0)
        # Average the logvars as well for consistency
        logvar = torch.stack(logvar_list, dim=0).mean(dim=0)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
        # Orthogonality penalty for decoders
        ortho_pen = torch.tensor(0.0, device=z.device)
        for dec in self.decoders.values():
            W = dec.lin.weight  # [E_i, k]
            G = W.T @ W
            I = torch.eye(G.shape[0], device=G.device)
            ortho_pen = ortho_pen + torch.norm(G - I, p='fro')**2
        
        loss = recon_loss + beta * kl + 1e-3 * ortho_pen
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}

def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)

    model = SRMVAE(batch.elec_num, k=VAE_K).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None

    for ep in range(1, epochs + 1):
        model.train()
        beta_ep = beta * min(1.0, ep / 500)  # warm-up over ~50 epochs
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta_ep)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}")

    if best_state is not None:
        model.load_state_dict(best_state)
    return model

# --- Stage 1: Adding new functions ---

# Task 1.2: Function to calculate baseline performance (Baseline)
def calculate_original_encoding(batch: LagBatch, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Calculates encoding performance on original ECoG data.
    The function runs on each subject and each electrode separately and returns the average correlation per subject.
    """
    print(f"  Calculating baseline encoding for lag {batch.lag_ms}ms...")
    
    # 1. Prepare word embeddings (PCA -> L2 norm)
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    
    results_per_subject = {}

    # 2. Loop over all subjects
    for s_id in batch.subjects:
        subject_data = batch.subject_views[s_id]
        Y_train = subject_data.train.cpu().numpy()
        Y_test = subject_data.test.cpu().numpy()
        
        # Use helper function for encoding calculation
        results_per_subject[s_id] = run_encoding_on_data(Y_train, Y_test, X_train_p, X_test_p)
            
    return results_per_subject

# Task 1.1: Full implementation of VAE analysis
def calculate_reconstructed_encoding_vae(batch: LagBatch, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Implements the full process: VAE training, signal reconstruction, and running encoding on reconstructed signals.
    """
    print(f"  Training SRM-VAE for lag {batch.lag_ms}ms...")
    
    # 1. Train SRM-VAE model
    model = train_srmvae_on_batch(batch, epochs=VAE_EPOCHS, lr=VAE_LR, beta=VAE_BETA, verbose=True)
    model.eval()
    
    # 2. Inference and reconstruction
    z_train, _, _ = model.infer_z(batch.subject_views, split="train", use_mu=True)
    z_test, _, _ = model.infer_z(batch.subject_views, split="test", use_mu=True)
    
    reconstructed_train_dict = model.reconstruct_subjects(z_train)
    reconstructed_test_dict = model.reconstruct_subjects(z_test)
    
    # 3. Prepare word embeddings
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    
    results_per_subject = {}
    
    # 4. Run encoding on reconstructed data using helper function
    for s_id in batch.subjects:
        Y_train_recon = reconstructed_train_dict[s_id].cpu().numpy()
        Y_test_recon = reconstructed_test_dict[s_id].cpu().numpy()
        
        results_per_subject[s_id] = run_encoding_on_data(Y_train_recon, Y_test_recon, X_train_p, X_test_p)
        
    return results_per_subject


# --- Task 4.1: New function for classic SRM ---
def calculate_reconstructed_encoding_srm(batch: LagBatch, k: int, pca_dim: int, seed: int) -> Dict[int, float]:
    """
    Calculates encoding performance using classic SRM from brainiak library.
    Fits SRM on training data and reconstructs signals for encoding evaluation.
    """
    print(f"  Fitting classic SRM for lag {batch.lag_ms}ms...")
    
    # Prepare data for brainiak (needs list of [electrodes, time] numpy arrays)
    train_data_list = [v.train.cpu().numpy().T for v in batch.subject_views.values()]
    test_data_list = [v.test.cpu().numpy().T for v in batch.subject_views.values()]

    # Fit SRM on training data
    srm = brainiak_srm.SRM(n_iter=20, features=k)
    srm.fit(train_data_list)

    # Transform data to shared space
    shared_train = srm.transform(train_data_list)
    shared_test = srm.transform(test_data_list)

    # Prepare word embeddings
    X_train_p, X_test_p = _prep_embeddings(batch.X_train.cpu().numpy(), batch.X_test.cpu().numpy(), pca_dim, seed)
    results = {}

    # Reconstruct and run encoding for each subject
    for i, s_id in enumerate(batch.subjects):
        w_subject = srm.w_[i]
        Y_train_recon = (w_subject @ shared_train[i]).T
        Y_test_recon = (w_subject @ shared_test[i]).T
        results[s_id] = run_encoding_on_data(Y_train_recon, Y_test_recon, X_train_p, X_test_p)
        
    return results


# --- Task 4.2: New plotting function ---
def plot_subject_results(subject_id, lags_list, all_original, all_srm, all_vae, elec_num_dict, plots_folder, plot_format, plot_dpi):
    """
    Creates a plot for a specific subject showing encoding performance across lags
    for all three methods: Original, Classic SRM, and SRM-VAE.
    Saves the plot to the specified folder instead of displaying it.
    """
    # Extract results for the specific subject
    original_r = [res[subject_id] for res in all_original]
    srm_r = [res[subject_id] for res in all_srm]
    vae_r = [res[subject_id] for res in all_vae]
    
    num_electrodes = elec_num_dict.get(subject_id, 'N/A')

    plt.figure(figsize=(5, 4))
    plt.plot(lags_list, original_r, label='Original', color='steelblue', linewidth=3)
    plt.plot(lags_list, srm_r, label='SRM (Classic)', color='darkorange', linewidth=3)
    plt.plot(lags_list, vae_r, label='SRM-VAE', color='green', linewidth=3)
    
    plt.axvline(0, ls='--', color='grey', alpha=0.7)
    plt.xlabel("lags (ms)")
    plt.ylabel("Encoding Performance (r)")
    plt.title(f"Encoding S{subject_id} ({num_electrodes} electrodes)")
    plt.legend()
    plt.ylim(bottom=0)
    plt.grid(True, linestyle=':', alpha=0.6)
    plt.tight_layout()
    
    # Save plot instead of showing it
    plot_filename = f"subject_{subject_id}_encoding.{plot_format}"
    plot_path = os.path.join(plots_folder, plot_filename)
    plt.savefig(plot_path, dpi=plot_dpi, bbox_inches='tight')
    plt.close()  # Close the figure to free memory
    
    print(f"  Saved plot for Subject {subject_id} to: {plot_path}")


# --- Main Execution Block ---
if __name__ == '__main__':
    set_global_seed(SEED)
    
    # Load data
    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
        print(f"Data loaded successfully. Y_data shape: {Y_data.shape}")
    except Exception as e:
        print(f"[ERROR] Failed to load data from {DATA_PATH}: {e}")
        exit()

    # Create subject list and electrode number dictionary
    subjects_list = list(range(1, len(elec_num) + 1))
    elec_num_dict = {s_id: num for s_id, num in zip(subjects_list, elec_num)}

    # Data structures to store results for all three methods
    all_original_results, all_srm_results, all_vae_results = [], [], []

    # Main loop over lags
    for lag_ms in LAG_LIST:
        print(f"\nProcessing Lag: {lag_ms}ms")
        
        # Prepare batch for current lag
        batch = build_lag_batch_from_loaded(Y_data, elec_num, X, lags, lag_ms, TRAIN_RATIO)
        
        # 1. Original encoding (baseline)
        original_results = calculate_original_encoding(batch, PCA_DIM, SEED)
        all_original_results.append(original_results)
        print(f"  > Original Avg r: {np.nanmean(list(original_results.values())):.4f}")

        # 2. Classic SRM encoding
        srm_results = calculate_reconstructed_encoding_srm(batch, SRM_K, PCA_DIM, SEED)
        all_srm_results.append(srm_results)
        print(f"  > Classic SRM Avg r: {np.nanmean(list(srm_results.values())):.4f}")

        # 3. SRM-VAE encoding
        vae_results = calculate_reconstructed_encoding_vae(batch, PCA_DIM, SEED)
        all_vae_results.append(vae_results)
        print(f"  > SRM-VAE Avg r: {np.nanmean(list(vae_results.values())):.4f}")

    print("\n--- Analysis Complete ---")
    print("Generating plots for each subject...")

    # Ensure plots folder exists
    plots_folder = ensure_plots_folder(PLOTS_FOLDER)

    # Generate a plot for each subject
    for s_id in subjects_list:
        plot_subject_results(
            s_id, LAG_LIST, all_original_results, all_srm_results, all_vae_results, 
            elec_num_dict, plots_folder, PLOT_FORMAT, PLOT_DPI
        )
    
    print(f"\nAll plots saved to: {plots_folder}")
    print("Analysis and plotting complete!") 
********************************************************************************

File: srm_vs_vae_shared_encoding.py
==================================================
# srm_vs_vae_shared_encoding.py
# Single-file comparison: classic SRM vs SRM-VAE
# - No CLI, no folds. Train/test split by time.
# - Evaluates a list of lags (ms) and plots shared-space encoding curves.

# ========= CONFIG (edit here) =========
DATA_PATH   = "./all_data.pkl"   # path to your all_data.pkl
SEED        = 1234               # random seed
TRAIN_RATIO = 0.8                # first 80% train, last 20% test
LAG_LIST    = [-2000, -1000, -500, 0, 100, 200, 300, 500, 1000, 1500, 1800]

 
SRM_K       = 5               
VAE_K       = 5                  

# Training / eval hyperparams
VAE_EPOCHS  = 1
VAE_LR      = 5e-3
VAE_BETA    = 0.5
PCA_DIM     = 50                  

# Plotting
YLIM        = (0.0, 0.40)
FIGSIZE     = (4.8, 3.5)
SAVE_PNG    = None              
# =====================================

import os
import sys
import math
import pickle
import random
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import matplotlib.pyplot as plt

# --- Torch
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
except Exception:
    print("ERROR: PyTorch not found. Install with: pip install torch")
    raise

# --- SciKit
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression

# --- BrainIAK SRM
try:
    from brainiak.funcalign import srm as brainiak_srm
except Exception:
    print("ERROR: BrainIAK not found. Install with: pip install brainiak")
    raise


# -----------------------------
# Reproducibility utilities
# -----------------------------
def set_global_seed(seed: int = 1234, deterministic: bool = True) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# -----------------------------
# Data structures
# -----------------------------
@dataclass
class SubjectView:
    """Time × Electrodes for one subject, already train/test split & normalized."""
    train: torch.Tensor  # [T_train, E_i]
    test:  torch.Tensor  # [T_test , E_i]
    mask_train: Optional[torch.Tensor] = None  # [E_i] (optional)
    mask_test:  Optional[torch.Tensor] = None  # [E_i] (optional)

@dataclass
class LagBatch:
    """Container for a single lag across all subjects and a simple time split."""
    lag_ms: int
    latent_dim: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor               # [T_train, D_emb]
    X_test:  torch.Tensor               # [T_test , D_emb]
    train_index: np.ndarray
    test_index:  np.ndarray
    elec_num: Dict[int, int]


# -----------------------------
# I/O and preprocessing
# -----------------------------

def load_all_data(pkl_path: str):
    """
    Expected keys in the pkl:
      - 'electrode_data': shape [S, L, T, Emax]
      - 'electrode_number': length S
      - 'word_embeddings': shape [T, D_emb]
      - 'lags': length L (ms)
    """
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])            # [S, L, T, Emax]
    elec_num = np.asarray(obj["electrode_number"], int)   # [S]
    X = np.asarray(obj["word_embeddings"])                # [T, D_emb]
    lags = np.asarray(obj["lags"]).reshape(-1)            # [L]
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    diffs = np.abs(lags_ms - target_ms)
    return int(np.argmin(diffs))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)  # ensure at least 1 test
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)


# -----------------------------
# Build a lag batch (from loaded arrays)
# -----------------------------

def build_lag_batch_from_loaded(
    Y_data: np.ndarray,
    elec_num: np.ndarray,
    X: np.ndarray,
    lags: np.ndarray,
    lag_ms: int,
    latent_dim: int,
    train_ratio: float,
) -> LagBatch:
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_index, test_index = time_split_indices(T, train_ratio)

    # Embeddings: PCA->L2 will be applied later, but we center here with train mean only.
    X_train = X[train_index, :]
    X_test  = X[test_index, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)

    subjects = list(range(1, S + 1))
    subject_views: Dict[int, SubjectView] = {}
    per_sub_elec: Dict[int, int] = {}

    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]   # [T, E_i]
        tr = mat[train_index, :]
        te = mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        mask = np.ones((e_i,), dtype=bool)

        subject_views[subjects[s]] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float(),
            mask_train=torch.from_numpy(mask),
            mask_test=torch.from_numpy(mask),
        )
        per_sub_elec[subjects[s]] = e_i

    return LagBatch(
        lag_ms=chosen_ms,
        latent_dim=latent_dim,
        subjects=subjects,
        subject_views=subject_views,
        X_train=torch.from_numpy(X_train).float(),
        X_test=torch.from_numpy(X_test).float(),
        train_index=train_index,
        test_index=test_index,
        elec_num=per_sub_elec,
    )


# -----------------------------
# SRM-VAE model
# -----------------------------
class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Identity()

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        # Simple averaging of means (like SRM) instead of precision-weighted aggregation
        mu = torch.stack(mu_list, dim=0).mean(dim=0)
        # Average the logvars as well for consistency
        logvar = torch.stack(logvar_list, dim=0).mean(dim=0)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
     
        ortho_pen = torch.tensor(0.0, device=z.device)
        for dec in self.decoders.values():
            W = dec.lin.weight  # [E_i, k]
            G = W.T @ W
            I = torch.eye(G.shape[0], device=G.device)
            ortho_pen = ortho_pen + torch.norm(G - I, p='fro')**2
        
        loss = recon_loss + beta * kl + 1e-3 * ortho_pen  # 
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}


# -----------------------------
# Training (VAE)
# -----------------------------

def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)
        if sv.mask_train is not None: sv.mask_train = sv.mask_train.to(dev)
        if sv.mask_test  is not None: sv.mask_test  = sv.mask_test.to(dev)

    model = SRMVAE(batch.elec_num, k=batch.latent_dim).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None

    for ep in range(1, epochs + 1):
        model.train()
        beta_ep = beta * min(1.0, ep / 500)  # warm-up over ~50 epochs
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta_ep)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}")

    if best_state is not None:
        model.load_state_dict(best_state)
    return model


# -----------------------------
# Shared-space encoding metrics (both methods)
# -----------------------------

def _prep_embeddings(X_train: np.ndarray, X_test: np.ndarray, pca_dim: int, seed: int):
    """PCA->L2 normalize rows. Fit PCA on train only."""
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p  = pca.transform(X_test)
    X_train_p = normalize(X_train_p, axis=1)
    X_test_p  = normalize(X_test_p, axis=1)
    return X_train_p, X_test_p, float(pca.explained_variance_ratio_.sum())

def _colwise_pearsonr(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

def shared_encoding_vae(batch: LagBatch, k: int, pca_dim: int, seed: int) -> Tuple[float, np.ndarray]:
    """Return (mean r over dims, r per dim) for SRM-VAE at this lag."""
    dev = torch_device()
    vae = train_srmvae_on_batch(batch, epochs=VAE_EPOCHS, lr=VAE_LR, beta=VAE_BETA, verbose=True)
    vae.eval()

    # Infer shared z (μ)
    z_tr, _, _ = vae.infer_z(batch.subject_views, split="train", use_mu=True)
    z_te, _, _ = vae.infer_z(batch.subject_views, split="test",  use_mu=True)
    z_train = z_tr.cpu().numpy()  # [T_train, k]
    z_test  = z_te.cpu().numpy()  # [T_test,  k]

    # Standardize z per dim
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    z_train_std = z_scaler.fit_transform(z_train)
    z_test_std  = z_scaler.transform(z_test)

    # Embeddings -> PCA+L2
    X_train_raw = batch.X_train.cpu().numpy()
    X_test_raw  = batch.X_test.cpu().numpy()
    X_train_p, X_test_p, _ = _prep_embeddings(X_train_raw, X_test_raw, pca_dim=pca_dim, seed=seed)

    # Linear map X -> z (multi-output regression)
    reg = LinearRegression()
    reg.fit(X_train_p, z_train_std)
    z_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(z_test_std, z_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return r_mean, r_dims


def shared_encoding_srm(Y_data: np.ndarray, elec_num: np.ndarray, X: np.ndarray,
                        lags: np.ndarray, lag_ms: int, train_ratio: float,
                        k: int, pca_dim: int, seed: int) -> Tuple[int, float, np.ndarray]:
    """
    Classic SRM baseline (brainiak):
    - Builds time-based train/test splits
    - Fits SRM on train data per subject
    - Averages shared time series across subjects
    - Regresses embeddings → shared dims and returns correlation per dim.
    Returns (chosen_lag_ms, mean r, r per dim)
    """
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_idx, test_idx = time_split_indices(T, train_ratio)

    # Prepare per-subject matrices
    train_data, test_data = [], []
    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]  # [T, E_i]
        tr = mat[train_idx, :]
        te = mat[test_idx, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        train_data.append(tr_z.T)  # [E_i, T_train]
        test_data.append(te_z.T)   # [E_i, T_test]

    # Fit SRM
    srm = brainiak_srm.SRM(n_iter=100, features=k)
    srm.fit(train_data)

    shared_train_list = srm.transform(train_data)
    shared_test_list  = srm.transform(test_data)

    s_train = np.mean(np.stack(shared_train_list, axis=0), axis=0).T  # [T_train, k]
    s_test  = np.mean(np.stack(shared_test_list,  axis=0), axis=0).T  # [T_test , k]

    # Standardize dims
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    s_train_std = z_scaler.fit_transform(s_train)
    s_test_std  = z_scaler.transform(s_test)

    # Embeddings -> PCA+L2
    X_train = X[train_idx, :]
    X_test  = X[test_idx, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)
    X_train_p, X_test_p, _ = _prep_embeddings(X_train, X_test, pca_dim=pca_dim, seed=seed)

    reg = LinearRegression()
    reg.fit(X_train_p, s_train_std)
    s_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(s_test_std, s_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return chosen_ms, r_mean, r_dims


# -----------------------------
# Multi-lag sweep + plot
# -----------------------------

def sweep_and_plot(Y_data, elec_num, X, lags, lag_list, srm_k, vae_k,
                   train_ratio, pca_dim, seed, ylim, figsize, save_png):
    dev = torch_device()
    print(f"[INFO] torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, device: {dev}")
    print(f"[DATA] Y={Y_data.shape}, X={X.shape}, lags_count={len(lags)}")
    print(f"[CONF] TRAIN_RATIO={train_ratio}, SRM_K={srm_k}, VAE_K={vae_k}, PCA_DIM={pca_dim}")

    srm_means, srm_sems, lag_actual_srm = [], [], []
    vae_means, vae_sems, lag_actual_vae = [], [], []

    for req in lag_list:
        # SRM baseline
        chosen_ms, srm_mean, srm_r_dims = shared_encoding_srm(
            Y_data, elec_num, X, lags,
            lag_ms=req, train_ratio=train_ratio,
            k=srm_k, pca_dim=pca_dim, seed=seed
        )
        srm_means.append(srm_mean)
        srm_sems.append(np.nanstd(srm_r_dims, ddof=1) / np.sqrt(len(srm_r_dims)))
        lag_actual_srm.append(chosen_ms)
        print(f"[SRM] lag req={req} -> chosen={chosen_ms} | r_mean={srm_mean:.3f}")

        # VAE baseline
        batch = build_lag_batch_from_loaded(
            Y_data, elec_num, X, lags,
            lag_ms=req, latent_dim=vae_k, train_ratio=train_ratio
        )
        vae_mean, vae_r_dims = shared_encoding_vae(batch, k=vae_k, pca_dim=pca_dim, seed=seed)
        vae_means.append(vae_mean)
        vae_sems.append(np.nanstd(vae_r_dims, ddof=1) / np.sqrt(len(vae_r_dims)))
        lag_actual_vae.append(batch.lag_ms)
        print(f"[VAE] lag req={req} -> chosen={batch.lag_ms} | r_mean={vae_mean:.3f}")

    x = np.asarray(lag_list, dtype=int)
    srm_means = np.asarray(srm_means)
    srm_sems  = np.asarray(srm_sems)
    vae_means = np.asarray(vae_means)
    vae_sems  = np.asarray(vae_sems)

    # Plot
    plt.figure(figsize=figsize)
    plt.fill_between(x, srm_means - srm_sems, srm_means + srm_sems, alpha=0.2, color='darkorange')
    plt.plot(x, srm_means, linewidth=3.5, label='SRM', color='darkorange')

    plt.fill_between(x, vae_means - vae_sems, vae_means + vae_sems, alpha=0.2, color='royalblue')
    plt.plot(x, vae_means, linewidth=3.5, label='VAE', color='royalblue')

    plt.axvline(0, ls='dashed', c='k', alpha=0.3)
    plt.ylim(ylim)
    plt.xlabel('lags (ms)')
    plt.ylabel('Encoding Performance (r)')
    plt.title('Shared Space Encoding')
    plt.legend()
    plt.tight_layout()

    if save_png:
        plt.savefig(save_png, dpi=150)
        print(f"[PLOT] Saved to {save_png}")
    plt.show()

    return {
        'x_requested': x,
        'srm': {'means': srm_means, 'sems': srm_sems, 'chosen_lags': lag_actual_srm},
        'vae': {'means': vae_means, 'sems': vae_sems, 'chosen_lags': lag_actual_vae},
    }


# -----------------------------
# Main
# -----------------------------

if __name__ == '__main__':
    set_global_seed(SEED, deterministic=True)
    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
    except Exception as e:
        print(f"[ERROR] Failed to load data: {e}")
        sys.exit(1)

    sweep_and_plot(
        Y_data=Y_data,
        elec_num=elec_num,
        X=X,
        lags=lags,
        lag_list=LAG_LIST,
        srm_k=SRM_K,
        vae_k=VAE_K,
        train_ratio=TRAIN_RATIO,
        pca_dim=PCA_DIM,
        seed=SEED,
        ylim=YLIM,
        figsize=FIGSIZE,
        save_png=SAVE_PNG,
    )

********************************************************************************

File: vae_srm_one_lag.py
==================================================
# vae_single_lag.py
# Train & evaluate the SRM-VAE on a SINGLE lag (default 20 ms).
# - No CLI, no folds. Simple time split by TRAIN_RATIO.
# - Prints reconstruction MSE per subject and shared-space encoding r.

# ========= CONFIG (edit here) =========
DATA_PATH   = "./all_data.pkl"   # path to your all_data.pkl
SEED        = 1234               # random seed
TRAIN_RATIO = 0.8                # first 80% train, last 20% test
LAG_MS      = 20                 # target lag (ms); uses closest available lag in the file

LATENT_K    = 5                # VAE shared latent dims
EPOCHS      = 400000
LR          =5e-4
BETA        = 2               # β-VAE weight

# For shared-space encoding evaluation (X -> z)
PCA_DIM     = 50                 # reduce embeddings to 50D then L2 row-normalize
VERBOSE     = True
SAVE_NPZ    = None               # e.g., "vae_single_lag_results.npz" or None
# =====================================

import os
import sys
import math
import pickle
import random
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np

# Torch
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
except Exception:
    print("ERROR: PyTorch not found. Install with: pip install torch")
    raise

# SciKit
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize, StandardScaler
from sklearn.linear_model import LinearRegression


# -----------------------------
# Reproducibility utilities
# -----------------------------
def set_global_seed(seed: int = 1234, deterministic: bool = True) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# -----------------------------
# Data structures
# -----------------------------
@dataclass
class SubjectView:
    """Time × Electrodes for one subject, already train/test split & normalized."""
    train: torch.Tensor  # [T_train, E_i]
    test:  torch.Tensor  # [T_test , E_i]
    mask_train: Optional[torch.Tensor] = None  # [E_i] (optional)
    mask_test:  Optional[torch.Tensor] = None  # [E_i] (optional)

@dataclass
class LagBatch:
    """Container for a single lag across all subjects and a simple time split."""
    lag_ms: int
    latent_dim: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor               # [T_train, D_emb]
    X_test:  torch.Tensor               # [T_test , D_emb]
    train_index: np.ndarray
    test_index:  np.ndarray
    elec_num: Dict[int, int]


# -----------------------------
# I/O and preprocessing
# -----------------------------
def load_all_data(pkl_path: str):
    """
    Expected keys:
      - 'electrode_data': [S, L, T, Emax]
      - 'electrode_number': [S]
      - 'word_embeddings': [T, D_emb]
      - 'lags': [L] (ms)
    """
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)
    Y_data = np.asarray(obj["electrode_data"])            # [S, L, T, Emax]
    elec_num = np.asarray(obj["electrode_number"], int)   # [S]
    X = np.asarray(obj["word_embeddings"])                # [T, D_emb]
    lags = np.asarray(obj["lags"]).reshape(-1)            # [L]
    return Y_data, elec_num, X, lags

def _zscore_train_apply(train: np.ndarray, test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    mu = train.mean(axis=0, keepdims=True)
    sd = train.std(axis=0, keepdims=True) + 1e-8
    return (train - mu) / sd, (test - mu) / sd

def choose_lag_index(lags_ms: np.ndarray, target_ms: int) -> int:
    diffs = np.abs(lags_ms - target_ms)
    return int(np.argmin(diffs))

def time_split_indices(T: int, train_ratio: float) -> Tuple[np.ndarray, np.ndarray]:
    n_train = max(1, int(round(T * train_ratio)))
    n_train = min(n_train, T - 1)  # ensure at least 1 test
    return np.arange(0, n_train, dtype=int), np.arange(n_train, T, dtype=int)


def build_lag_batch_from_loaded(
    Y_data: np.ndarray,
    elec_num: np.ndarray,
    X: np.ndarray,
    lags: np.ndarray,
    lag_ms: int,
    latent_dim: int,
    train_ratio: float,
) -> LagBatch:
    """Build a single-lag batch with z-scoring per subject and centered embeddings."""
    S, L, T, Emax = Y_data.shape
    lag_idx = choose_lag_index(lags, lag_ms)
    chosen_ms = int(lags[lag_idx])

    train_index, test_index = time_split_indices(T, train_ratio)

    # Embeddings: center by train mean only
    X_train = X[train_index, :]
    X_test  = X[test_index, :]
    X_train = X_train - X_train.mean(axis=0, keepdims=True)
    X_test  = X_test  - X_train.mean(axis=0, keepdims=True)

    subjects = list(range(1, S + 1))
    subject_views: Dict[int, SubjectView] = {}
    per_sub_elec: Dict[int, int] = {}

    for s in range(S):
        e_i = int(elec_num[s])
        mat = Y_data[s, lag_idx, :, :e_i]   # [T, E_i]
        tr = mat[train_index, :]
        te = mat[test_index, :]
        tr_z, te_z = _zscore_train_apply(tr, te)
        mask = np.ones((e_i,), dtype=bool)

        subject_views[subjects[s]] = SubjectView(
            train=torch.from_numpy(tr_z).float(),
            test=torch.from_numpy(te_z).float(),
            mask_train=torch.from_numpy(mask),
            mask_test=torch.from_numpy(mask),
        )
        per_sub_elec[subjects[s]] = e_i

    return LagBatch(
        lag_ms=chosen_ms,
        latent_dim=latent_dim,
        subjects=subjects,
        subject_views=subject_views,
        X_train=torch.from_numpy(X_train).float(),
        X_test=torch.from_numpy(X_test).float(),
        train_index=train_index,
        test_index=test_index,
        elec_num=per_sub_elec,
    )


# -----------------------------
# SRM-VAE model
# -----------------------------
class PerSubjectEncoder(nn.Module):
    """Linear encoder per subject: R^{E_i} -> (mu, logvar) in R^k"""
    def __init__(self, e_i: int, k: int):
        super().__init__()
        self.lin = nn.Linear(e_i, 2 * k, bias=True)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        h = self.lin(x)  # [T, 2k]
        mu, logvar = torch.chunk(h, 2, dim=-1)
        return mu, logvar.clamp(min=-8.0, max=8.0)

class PerSubjectDecoder(nn.Module):
    """Linear decoder per subject: R^k -> R^{E_i}"""
    def __init__(self, k: int, e_i: int):
        super().__init__()
        self.lin = nn.Linear(k, e_i, bias=False)
        nn.init.xavier_uniform_(self.lin.weight)
    def forward(self, zf: torch.Tensor) -> torch.Tensor:
        return self.lin(zf)

class SRMVAE(nn.Module):
    """
    Encoders per subject -> precision-weighted group posterior -> shared core f(z)
    -> decoders per subject (SRM-like).
    """
    def __init__(self, elec_num: Dict[int, int], k: int):
        super().__init__()
        self.k = k
        self.encoders = nn.ModuleDict()
        self.decoders = nn.ModuleDict()
        for sid, e_i in elec_num.items():
            self.encoders[str(sid)] = PerSubjectEncoder(e_i, k)
            self.decoders[str(sid)] = PerSubjectDecoder(k, e_i)
        self.core = nn.Sequential(nn.Linear(k, k), nn.ReLU(), nn.Linear(k, k))
        for m in self.core:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)

    @staticmethod
    def _agg_posteriors(mu_list, logvar_list):
        precisions = [torch.exp(-lv) for lv in logvar_list]
        prec_sum = torch.stack(precisions, dim=0).sum(dim=0)
        weighted_mu = torch.stack([m * p for m, p in zip(mu_list, precisions)], dim=0).sum(dim=0)
        var = 1.0 / (prec_sum + 1e-8)
        mu = var * weighted_mu
        logvar = torch.log(var + 1e-8)
        return mu, logvar

    def encode_group(self, subject_views: Dict[int, SubjectView], split: str):
        mu_list, logvar_list = [], []
        for sid, view in subject_views.items():
            x = getattr(view, split)  # [T,E_i]
            mu_i, logvar_i = self.encoders[str(sid)](x)
            mu_list.append(mu_i)
            logvar_list.append(logvar_i)
        return self._agg_posteriors(mu_list, logvar_list)

    def forward(self, subject_views: Dict[int, SubjectView], split: str, beta: float = 1.0):
        mu, logvar = self.encode_group(subject_views, split)
        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        zf = self.core(z)
        # tensor (not python float) for stability
        recon_loss = torch.tensor(0.0, device=z.device)
        for sid, view in subject_views.items():
            x = getattr(view, split)           # [T,E_i]
            x_hat = self.decoders[str(sid)](zf)
            recon_loss = recon_loss + F.mse_loss(x_hat, x, reduction='mean')
        kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        loss = recon_loss + beta * kl
        return loss, recon_loss.detach(), kl.detach()

    @torch.no_grad()
    def infer_z(self, subject_views: Dict[int, SubjectView], split: str, use_mu: bool = True):
        mu, logvar = self.encode_group(subject_views, split)
        if use_mu:
            z = mu
        else:
            z = mu + torch.exp(0.5 * logvar) * torch.randn_like(mu)
        return z, mu, logvar

    @torch.no_grad()
    def reconstruct_subjects(self, z: torch.Tensor) -> Dict[int, torch.Tensor]:
        zf = self.core(z)
        return {int(sid): dec(zf) for sid, dec in self.decoders.items()}


# -----------------------------
# Training
# -----------------------------
def train_srmvae_on_batch(batch: LagBatch, epochs: int, lr: float, beta: float, verbose: bool = True) -> SRMVAE:
    dev = torch_device()
    for sid in batch.subjects:
        sv = batch.subject_views[sid]
        sv.train = sv.train.to(dev)
        sv.test  = sv.test.to(dev)
        if sv.mask_train is not None: sv.mask_train = sv.mask_train.to(dev)
        if sv.mask_test  is not None: sv.mask_test  = sv.mask_test.to(dev)

    model = SRMVAE(batch.elec_num, k=batch.latent_dim).to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    best_loss = math.inf
    best_state = None
    patience = math.inf
    no_imp = 0

    for ep in range(1, epochs + 1):
        model.train()
        loss, rec, kl = model(batch.subject_views, split="train", beta=beta)
        opt.zero_grad(set_to_none=True)
        loss.backward()
        opt.step()

        curr = float(loss.item())
        if curr < best_loss - 1e-5:
            best_loss = curr
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
            no_imp = 0
        else:
            no_imp += 1

        if verbose and (ep % 25 == 0 or ep == 1):
            print(f"[ep {ep:03d}] loss={curr:.5f}  rec={float(rec):.5f}  kl={float(kl):.5f}  no_imp={no_imp}")

        if no_imp >= patience:
            if verbose:
                print(f"[early stop] best_loss={best_loss:.5f} at ep≈{ep-no_imp}")
            break

    if best_state is not None:
        model.load_state_dict(best_state)
    return model


# -----------------------------
# Evaluation helpers
# -----------------------------
def _prep_embeddings(X_train: np.ndarray, X_test: np.ndarray, pca_dim: int, seed: int):
    """PCA -> L2 normalize rows. Fit PCA on train only."""
    pca = PCA(n_components=pca_dim, svd_solver="auto", random_state=seed)
    X_train_p = pca.fit_transform(X_train)
    X_test_p  = pca.transform(X_test)
    X_train_p = normalize(X_train_p, axis=1)
    X_test_p  = normalize(X_test_p, axis=1)
    return X_train_p, X_test_p, float(pca.explained_variance_ratio_.sum())

def _colwise_pearsonr(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8):
    yt = y_true - y_true.mean(axis=0, keepdims=True)
    yp = y_pred - y_pred.mean(axis=0, keepdims=True)
    num = (yt * yp).sum(axis=0)
    den = np.sqrt((yt**2).sum(axis=0) * (yp**2).sum(axis=0)) + eps
    return num / den

def eval_encoding_PCA_Ridge(batch: LagBatch, vae: SRMVAE, pca_dim: int = 50, seed: int = SEED):
    """Shared-space encoding: regress PCA+L2(X) -> standardized μ(z) on train; eval on test."""
    dev = torch_device()
    vae.eval()
    with torch.no_grad():
        z_tr, _, _ = vae.infer_z(batch.subject_views, split="train", use_mu=True)
        z_te, _, _ = vae.infer_z(batch.subject_views, split="test",  use_mu=True)
    z_train = z_tr.cpu().numpy()  # [T_train, k]
    z_test  = z_te.cpu().numpy()  # [T_test,  k]

    # Standardize z (train stats only)
    z_scaler = StandardScaler(with_mean=True, with_std=True)
    z_train_std = z_scaler.fit_transform(z_train)
    z_test_std  = z_scaler.transform(z_test)

    # Embeddings: PCA(pca_dim) + L2 per row
    X_train_raw = batch.X_train.cpu().numpy()
    X_test_raw  = batch.X_test.cpu().numpy()
    X_train_p, X_test_p, pca_var = _prep_embeddings(X_train_raw, X_test_raw, pca_dim=pca_dim, seed=seed)

    # Linear regression X -> z
    reg = LinearRegression()
    reg.fit(X_train_p, z_train_std)
    z_hat_test_std = reg.predict(X_test_p)

    r_dims = _colwise_pearsonr(z_test_std, z_hat_test_std)
    r_mean = float(np.nanmean(r_dims))
    return {
        "r_z_mean": r_mean,
        "r_z_dims": r_dims,
        "pca_explained": pca_var,
    }


# -----------------------------
# Main
# -----------------------------
if __name__ == "__main__":
    set_global_seed(SEED, deterministic=True)
    dev = torch_device()
    print(f"[INFO] torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, device: {dev}")
    print(f"[INFO] DATA_PATH={DATA_PATH} | LATENT_K={LATENT_K} | TRAIN_RATIO={TRAIN_RATIO} | LAG_MS(target)={LAG_MS}")

    try:
        Y_data, elec_num, X, lags = load_all_data(DATA_PATH)
    except Exception as e:
        print(f"[ERROR] Failed to load data: {e}")
        sys.exit(1)

    # Build single-lag batch (closest to LAG_MS)
    batch = build_lag_batch_from_loaded(
        Y_data=Y_data,
        elec_num=elec_num,
        X=X,
        lags=lags,
        lag_ms=LAG_MS,
        latent_dim=LATENT_K,
        train_ratio=TRAIN_RATIO,
    )
    print(f"[OK] using lag_ms={batch.lag_ms} (closest to {LAG_MS})")
    s1 = batch.subjects[0]
    print(f"     S{s1} train shape: {tuple(batch.subject_views[s1].train.shape)}")
    print(f"     X_train: {tuple(batch.X_train.shape)}  X_test: {tuple(batch.X_test.shape)}")

    # Train VAE
    print(f"[TRAIN] SRM-VAE on lag={batch.lag_ms} ms, k={batch.latent_dim}")
    vae = train_srmvae_on_batch(batch, epochs=EPOCHS, lr=LR, beta=BETA, verbose=VERBOSE)

    # Inference & quick reconstruction MSEs on test
    vae.eval()
    with torch.no_grad():
        z_te, _, _ = vae.infer_z(batch.subject_views, split="test", use_mu=True)
        recons_test = vae.reconstruct_subjects(z_te.to(dev))
        for sid in batch.subjects:
            x_true = batch.subject_views[sid].test.to(dev)
            x_hat  = recons_test[sid]
            mse = F.mse_loss(x_hat, x_true).item()
            print(f"[TEST] Subject {sid}: recon MSE = {mse:.6f}")

    # Shared-space encoding eval (X -> z)
    print(f"[EVAL] PCA({PCA_DIM})+Linear encoding to z")
    enc = eval_encoding_PCA_Ridge(batch, vae, pca_dim=PCA_DIM, seed=SEED)
    print(f"[ENC] Shared-space r (mean over k={LATENT_K}): {enc['r_z_mean']:.4f}  | PCA var={enc['pca_explained']:.2f}")

    if SAVE_NPZ:
        np.savez(
            SAVE_NPZ,
            lag_ms=batch.lag_ms,
            r_z_mean=enc["r_z_mean"],
            r_z_dims=enc["r_z_dims"],
            latent_k=LATENT_K,
            train_ratio=TRAIN_RATIO,
            pca_dim=PCA_DIM,
        )
        print(f"[SAVE] Wrote metrics to {SAVE_NPZ}")

********************************************************************************

File: vae_vs_srm_generalization.py
==================================================
# vae_vs_srm_generalization.py
# --- CONFIG (editable) ---
DATA_PATH   = "./all_data.pkl"
SEED        = 1234
TRAIN_RATIO = 0.8
LAG_LIST    = [-500, 0, 200, 500]  # Lags to test (ms)
PCA_DIM     = 50

# Directory to save plots
OUTPUT_DIR  = "shared_space_plots"

# --- Imports ---
import os, pickle, random
from typing import Dict, List
from dataclasses import dataclass

import numpy as np
import torch, torch.nn as nn, torch.nn.functional as F
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from brainiak.funcalign import srm as brainiak_srm

# Create output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Shared dimension and VAE hyper-parameters
SHARED_K   = 5
VAE_EPOCHS = 500
VAE_LR     = 1e-3
VAE_BETA   = 0.1

# ----------------- helpers -----------------

def set_global_seed(seed=1234):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

def torch_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

@dataclass
class SubjectView:
    train: torch.Tensor
    test:  torch.Tensor
    elec_num: int = 0

@dataclass
class LagBatch:
    lag_ms: int
    subjects: List[int]
    subject_views: Dict[int, SubjectView]
    X_train: torch.Tensor
    X_test:  torch.Tensor
    elec_num: Dict[int,int]

# ------------- IO -------------

def load_all_data(path):
    with open(path, "rb") as f:
        obj = pickle.load(f)
    return (np.asarray(obj["electrode_data"]),
            np.asarray(obj["electrode_number"], int),
            np.asarray(obj["word_embeddings"]),
            np.asarray(obj["lags"]).reshape(-1))

# ------------- preprocessing -------------

def _prep_embeddings(Xtr, Xte, pca_dim, seed):
    pca = PCA(n_components=pca_dim, random_state=seed)
    Xtr_p = pca.fit_transform(Xtr)
    Xte_p = pca.transform(Xte)
    return normalize(Xtr_p, axis=1), normalize(Xte_p, axis=1)

def _zscore_train_apply(tr, te):
    mu = tr.mean(0, keepdims=True); sd = tr.std(0, keepdims=True)+1e-8
    return (tr-mu)/sd, (te-mu)/sd

def choose_lag_index(lags_ms, target_ms):
    return int(np.argmin(np.abs(lags_ms-target_ms)))

def time_split_indices(T, ratio):
    n = min(max(1,int(round(T*ratio))), T-1)
    return np.arange(n), np.arange(n, T)

# ------------- VAE-SRM model -------------
class Enc(nn.Module):
    def __init__(self,e_i,k): super().__init__(); self.lin=nn.Linear(e_i,2*k); nn.init.xavier_uniform_(self.lin.weight)
    def forward(self,x): return torch.chunk(self.lin(x),2,-1)
class Dec(nn.Module):
    def __init__(self,k,e_i): super().__init__(); self.lin=nn.Linear(k,e_i,bias=False); nn.init.xavier_uniform_(self.lin.weight)
    def forward(self,z): return self.lin(z)
class SRMVAE(nn.Module):
    def __init__(self,elec_num:Dict[int,int],k:int):
        super().__init__()
        self.encoders=nn.ModuleDict({str(s):Enc(e,k) for s,e in elec_num.items()})
        self.decoders=nn.ModuleDict({str(s):Dec(k,e) for s,e in elec_num.items()})
    @staticmethod
    def _agg(mu_list,lv_list):
        prec=[torch.exp(-lv) for lv in lv_list]; tot=torch.stack(prec,0).sum(0)+1e-8
        mu=torch.stack([m*p for m,p in zip(mu_list,prec)],0).sum(0)/tot
        return mu, -torch.log(tot)
    def encode_group(self,views,split):
        mus,lvs=[],[]
        for sid_str,enc in self.encoders.items():
            sid=int(sid_str)
            if sid in views:
                mu,lv=enc(getattr(views[sid],split))
                mus.append(mu); lvs.append(lv)
        return self._agg(mus,lvs)
    def forward(self,views,beta):
        mu,lv=self.encode_group(views,"train")
        z=mu+torch.exp(0.5*lv)*torch.randn_like(mu)
        rec=sum(F.mse_loss(self.decoders[sid_str](z), views[int(sid_str)].train)
                for sid_str in self.decoders.keys() if int(sid_str) in views)
        kl=-0.5*torch.mean(1+lv-mu.pow(2)-lv.exp())
        return rec+beta*kl
    @torch.no_grad()
    def infer_z(self,views,split):
        return self.encode_group(views,split)[0]

def train_vae(batch,k,epochs,lr,beta):
    dev=torch_device()
    for v in batch.subject_views.values(): v.train,v.test=v.train.to(dev),v.test.to(dev)
    model=SRMVAE(batch.elec_num,k).to(dev)
    opt=torch.optim.Adam(model.parameters(),lr=lr)
    for _ in range(epochs):
        opt.zero_grad(); loss=model(batch.subject_views,beta); loss.backward(); opt.step()
    return model

# ------------- batch builder -------------

def build_batches(Y,elec,X,lags,lag_ms,ratio,test_sid):
    S,_,T,_=Y.shape
    idx=choose_lag_index(lags,lag_ms)
    tr,te=time_split_indices(T,ratio)
    Xtr,Xte=X[tr],X[te]
    Xtr-=Xtr.mean(0,keepdims=True); Xte-=Xtr.mean(0,keepdims=True)
    train_sids=[s for s in range(1,S+1) if s!=test_sid]
    views,elec_dict={},{}
    for sid in train_sids:
        e=int(elec[sid-1]); mat=Y[sid-1,idx,:,:e]
        tr_z, te_z = _zscore_train_apply(mat[tr], mat[te])
        views[sid] = SubjectView(torch.tensor(tr_z, dtype=torch.float32),
                                 torch.tensor(te_z, dtype=torch.float32))
        elec_dict[sid] = e
    batch = LagBatch(int(lags[idx]),
                     train_sids,
                     views,
                     torch.tensor(Xtr, dtype=torch.float32),
                     torch.tensor(Xte, dtype=torch.float32),
                     elec_dict)
    e_test=int(elec[test_sid-1]); mat_t=Y[test_sid-1,idx,:,:e_test]
    tr_z_t, te_z_t = _zscore_train_apply(mat_t[tr], mat_t[te])
    test_view = SubjectView(torch.tensor(tr_z_t, dtype=torch.float32),
                            torch.tensor(te_z_t, dtype=torch.float32),
                            elec_num=e_test)
    return batch,test_view

# ------------- analyses -------------

def vae_generalization(batch,test_view):
    model=train_vae(batch,SHARED_K,VAE_EPOCHS,VAE_LR,VAE_BETA).eval()
    z_train=model.infer_z(batch.subject_views,"train").cpu().numpy()
    Xtr_p,Xte_p=_prep_embeddings(batch.X_train.numpy(),batch.X_test.numpy(),PCA_DIM,SEED)
    enc=LinearRegression().fit(Xtr_p,z_train)
    z_pred=enc.predict(Xte_p)
    Ytr=test_view.train.numpy(); W,_,_,_=np.linalg.lstsq(Ytr,z_train,rcond=None)
    z_true=test_view.test.numpy() @ W
    vx,vy=z_true-z_true.mean(0), z_pred-z_pred.mean(0)
    r=np.sum(vx*vy,0)/(np.sqrt(np.sum(vx**2,0))*np.sqrt(np.sum(vy**2,0))+1e-8)
    return float(np.nanmean(r))

# Classic SRM generalization with safe device transfers
def srm_generalization(batch, test_view):
    train_data = [v.train.cpu().numpy().T for v in batch.subject_views.values()]
    self_tr = test_view.train.cpu().numpy().T
    self_te = test_view.test.cpu().numpy().T
    srm=brainiak_srm.SRM(n_iter=50,features=SHARED_K); srm.fit(train_data)
    shared_train=srm.s_.T
    Xtr_p,Xte_p=_prep_embeddings(batch.X_train.numpy(),batch.X_test.numpy(),PCA_DIM,SEED)
    enc=LinearRegression().fit(Xtr_p,shared_train)
    z_pred=enc.predict(Xte_p)
    W=self_tr @ shared_train @ np.linalg.inv(shared_train.T @ shared_train)
    z_true=(W.T @ self_te).T
    vx,vy=z_true-z_true.mean(0), z_pred-z_pred.mean(0)
    r=np.sum(vx*vy,0)/(np.sqrt(np.sum(vx**2,0))*np.sqrt(np.sum(vy**2,0))+1e-8)
    return float(np.nanmean(r))

# ------------- main -------------
if __name__=="__main__":
    set_global_seed(SEED)
    Y,elec,X,lags=load_all_data(DATA_PATH)
    subjects=list(range(1,len(elec)+1))
    scores_vae={s:{} for s in subjects}; scores_srm={s:{} for s in subjects}

    for sid in subjects:
        print(f"\n>>> Subject {sid}")
        for lag in LAG_LIST:
            batch,test_view=build_batches(Y,elec,X,lags,lag,TRAIN_RATIO,sid)
            r_vae=vae_generalization(batch,test_view)
            r_srm=srm_generalization(batch,test_view)
            scores_vae[sid][lag]=r_vae; scores_srm[sid][lag]=r_srm
            print(f"  lag {lag:4d} | VAE {r_vae:.3f} | SRM {r_srm:.3f}")

    # ---------- plotting per subject ----------
    for sid in subjects:
        plt.figure(figsize=(5.2,3.6))
        lags=LAG_LIST
        plt.plot(lags,[scores_vae[sid][l] for l in lags],'-o',label='VAE',color='dodgerblue')
        plt.plot(lags,[scores_srm[sid][l] for l in lags],'-o',label='SRM',color='darkorange')
        plt.axvline(0,ls="--",color='grey',alpha=0.5)
        plt.title(f'Subject {sid}'); plt.xlabel('lag (ms)'); plt.ylabel('generalization r')
        plt.legend(); plt.tight_layout();
        plt.savefig(f"{OUTPUT_DIR}/subject_{sid}_vae_vs_srm.png", dpi=300)
        plt.close()

    # ---------- combined plot ----------
    colors=plt.cm.tab10(np.linspace(0,1,len(subjects)))
    plt.figure(figsize=(6,4))
    for i,sid in enumerate(subjects):
        plt.plot(LAG_LIST,[scores_vae[sid][l] for l in LAG_LIST],color=colors[i],lw=1.8,label=f'S{sid}')
    plt.axvline(0,ls='--',color='grey',alpha=0.6); plt.title('All subjects – VAE'); plt.xlabel('lag (ms)'); plt.ylabel('r'); plt.legend(ncol=2,fontsize=8); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/all_subjects_vae_only.png", dpi=300)
    plt.close()

    # ---------- averages ----------
    def mean_sem(score_dict):
        mean,sem=[],[]
        for l in LAG_LIST:
            arr=np.array([score_dict[sid][l] for sid in subjects])
            mean.append(arr.mean()); sem.append(arr.std(ddof=1)/np.sqrt(len(arr)))
        return np.array(mean),np.array(sem)
    m_vae,se_vae=mean_sem(scores_vae); m_srm,se_srm=mean_sem(scores_srm)
    plt.figure(figsize=(6,4))
    plt.plot(LAG_LIST,m_vae,color='dodgerblue',lw=3,label='VAE'); plt.fill_between(LAG_LIST,m_vae-se_vae,m_vae+se_vae,color='dodgerblue',alpha=0.25)
    plt.plot(LAG_LIST,m_srm,color='darkorange',lw=3,label='SRM'); plt.fill_between(LAG_LIST,m_srm-se_srm,m_srm+se_srm,color='darkorange',alpha=0.25)
    plt.axvline(0,ls='--',color='grey',alpha=0.6)
    plt.xlabel('lag (ms)'); plt.ylabel('mean r ± sem'); plt.title('VAE vs classic SRM – average'); plt.legend(); plt.grid(True,linestyle=':',alpha=0.5); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/averages_vae_vs_srm.png", dpi=300)
    plt.close()

    # ---------- combined subjects plot ----------
    fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
    colors = plt.cm.viridis(np.linspace(0, 1, len(subjects)))
    # VAE Plot
    axes[0].set_title('All Subjects: VAE Generalization')
    for i, sid in enumerate(subjects):
        lags_sorted = sorted(scores_vae[sid].keys())
        scores_sorted = [scores_vae[sid][lag] for lag in lags_sorted]
        axes[0].plot(lags_sorted, scores_sorted, color=colors[i], lw=2, label=f'Subject {sid}')
    # SRM Plot
    axes[1].set_title('All Subjects: Classic SRM Generalization')
    for i, sid in enumerate(subjects):
        lags_sorted = sorted(scores_srm[sid].keys())
        scores_sorted = [scores_srm[sid][lag] for lag in lags_sorted]
        axes[1].plot(lags_sorted, scores_sorted, color=colors[i], lw=2, label=f'Subject {sid}')
    for ax in axes:
        ax.axvline(0, ls="--", color="grey", alpha=0.6)
        ax.set_xlabel('lag (ms)'); ax.grid(True, linestyle=":", alpha=0.5); ax.legend()
    axes[0].set_ylabel('Generalization Performance (r)'); plt.tight_layout()
    fig.savefig(f"{OUTPUT_DIR}/all_subjects_vae_vs_srm.png", dpi=300)
    plt.close(fig)

    # Create the plot
    plt.figure(figsize=(7, 5))
    plt.plot(LAG_LIST, m_vae, color="dodgerblue", lw=3, label="VAE Generalization (Avg)")
    plt.fill_between(LAG_LIST, m_vae - se_vae, m_vae + se_vae, color="dodgerblue", alpha=0.2)
    plt.plot(LAG_LIST, m_srm, color="darkorange", lw=3, label="Classic SRM Generalization (Avg)")
    plt.fill_between(LAG_LIST, m_srm - se_srm, m_srm + se_srm, color="darkorange", alpha=0.2)
    plt.axvline(0, ls="--", color="grey", alpha=0.6); plt.xlabel("lag (ms)"); plt.ylabel("Avg. Generalization Performance (r)")
    plt.title("Comparison of Average Generalization Performance"); plt.grid(True, linestyle=":", alpha=0.5)
    plt.legend(); plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/average_vae_vs_srm.png", dpi=300)
    plt.close()